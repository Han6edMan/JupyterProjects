{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "descending-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_datasets.image_classification.imagenet as imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-switzerland",
   "metadata": {},
   "source": [
    "help(imagenet)\n",
    "\n",
    "Help on module tensorflow_datasets.image_classification.imagenet in tensorflow_datasets.image_classification:\n",
    "\n",
    "NAME\n",
    "    tensorflow_datasets.image_classification.imagenet - Imagenet datasets.\n",
    "\n",
    "CLASSES\n",
    "    tensorflow_datasets.core.dataset_builder.GeneratorBasedBuilder(tensorflow_datasets.core.dataset_builder.FileReaderBuilder)\n",
    "        Imagenet2012\n",
    "    \n",
    "    class Imagenet2012(tensorflow_datasets.core.dataset_builder.GeneratorBasedBuilder)\n",
    "     |  Imagenet2012(*, file_format: Union[NoneType, str, tensorflow_datasets.core.file_adapters.FileFormat] = <FileFormat.TFRECORD: 'tfrecord'>, **kwargs: Any)\n",
    "     |  \n",
    "     |  Imagenet 2012, aka ILSVRC 2012.\n",
    "     |  \n",
    "     |  Method resolution order:\n",
    "     |      Imagenet2012\n",
    "     |      tensorflow_datasets.core.dataset_builder.GeneratorBasedBuilder\n",
    "     |      tensorflow_datasets.core.dataset_builder.FileReaderBuilder\n",
    "     |      tensorflow_datasets.core.dataset_builder.DatasetBuilder\n",
    "     |      tensorflow_datasets.core.registered.RegisteredDataset\n",
    "     |      abc.ABC\n",
    "     |      builtins.object\n",
    "     |  \n",
    "     |  Data and other attributes defined here:\n",
    "     |  \n",
    "     |  MANUAL_DOWNLOAD_INSTRUCTIONS = '  manual_dir should contain two files:...\n",
    "     |  \n",
    "     |  RELEASE_NOTES = {'2.0.0': 'Fix validation labels.', '2.0.1': 'Encoding...\n",
    "     |  \n",
    "     |  SUPPORTED_VERSIONS = [Version('5.0.0')]\n",
    "     |  \n",
    "     |  VERSION = Version('5.1.0')\n",
    "     |  \n",
    "     |  __abstractmethods__ = frozenset()\n",
    "     |  \n",
    "     |  name = 'imagenet2012'\n",
    "     |  \n",
    "     |  ----------------------------------------------------------------------\n",
    "     |  Methods inherited from tensorflow_datasets.core.dataset_builder.FileReaderBuilder:\n",
    "     |  \n",
    "     |  __init__(self, *, file_format: Union[NoneType, str, tensorflow_datasets.core.file_adapters.FileFormat] = <FileFormat.TFRECORD: 'tfrecord'>, **kwargs: Any)\n",
    "     |      Initializes an instance of FileReaderBuilder.\n",
    "     |      \n",
    "     |      Callers must pass arguments as keyword arguments.\n",
    "     |      \n",
    "     |      Args:\n",
    "     |        file_format: EXPERIMENTAL, may change at any time; Format of the record\n",
    "     |          files in which dataset will be read/written to. Defaults to `tfrecord`.\n",
    "     |        **kwargs: Arguments passed to `DatasetBuilder`.\n",
    "     |  \n",
    "     |  ----------------------------------------------------------------------\n",
    "     |  Methods inherited from tensorflow_datasets.core.dataset_builder.DatasetBuilder:\n",
    "     |  \n",
    "     |  __getstate__(self)\n",
    "     |  \n",
    "     |  __setstate__(self, state)\n",
    "     |  \n",
    "     |  as_dataset(self, split=None, *, batch_size=None, shuffle_files=False, decoders=None, read_config=None, as_supervised=False)\n",
    "     |      Constructs a `tf.data.Dataset`.\n",
    "     |      \n",
    "     |      Callers must pass arguments as keyword arguments.\n",
    "     |      \n",
    "     |      The output types vary depending on the parameters. Examples:\n",
    "     |      \n",
    "     |      ```python\n",
    "     |      builder = tfds.builder('imdb_reviews')\n",
    "     |      builder.download_and_prepare()\n",
    "     |      \n",
    "     |      # Default parameters: Returns the dict of tf.data.Dataset\n",
    "     |      ds_all_dict = builder.as_dataset()\n",
    "     |      assert isinstance(ds_all_dict, dict)\n",
    "     |      print(ds_all_dict.keys())  # ==> ['test', 'train', 'unsupervised']\n",
    "     |      \n",
    "     |      assert isinstance(ds_all_dict['test'], tf.data.Dataset)\n",
    "     |      # Each dataset (test, train, unsup.) consists of dictionaries\n",
    "     |      # {'label': <tf.Tensor: .. dtype=int64, numpy=1>,\n",
    "     |      #  'text': <tf.Tensor: .. dtype=string, numpy=b\"I've watched the movie ..\">}\n",
    "     |      # {'label': <tf.Tensor: .. dtype=int64, numpy=1>,\n",
    "     |      #  'text': <tf.Tensor: .. dtype=string, numpy=b'If you love Japanese ..'>}\n",
    "     |      \n",
    "     |      # With as_supervised: tf.data.Dataset only contains (feature, label) tuples\n",
    "     |      ds_all_supervised = builder.as_dataset(as_supervised=True)\n",
    "     |      assert isinstance(ds_all_supervised, dict)\n",
    "     |      print(ds_all_supervised.keys())  # ==> ['test', 'train', 'unsupervised']\n",
    "     |      \n",
    "     |      assert isinstance(ds_all_supervised['test'], tf.data.Dataset)\n",
    "     |      # Each dataset (test, train, unsup.) consists of tuples (text, label)\n",
    "     |      # (<tf.Tensor: ... dtype=string, numpy=b\"I've watched the movie ..\">,\n",
    "     |      #  <tf.Tensor: ... dtype=int64, numpy=1>)\n",
    "     |      # (<tf.Tensor: ... dtype=string, numpy=b\"If you love Japanese ..\">,\n",
    "     |      #  <tf.Tensor: ... dtype=int64, numpy=1>)\n",
    "     |      \n",
    "     |      # Same as above plus requesting a particular split\n",
    "     |      ds_test_supervised = builder.as_dataset(as_supervised=True, split='test')\n",
    "     |      assert isinstance(ds_test_supervised, tf.data.Dataset)\n",
    "     |      # The dataset consists of tuples (text, label)\n",
    "     |      # (<tf.Tensor: ... dtype=string, numpy=b\"I've watched the movie ..\">,\n",
    "     |      #  <tf.Tensor: ... dtype=int64, numpy=1>)\n",
    "     |      # (<tf.Tensor: ... dtype=string, numpy=b\"If you love Japanese ..\">,\n",
    "     |      #  <tf.Tensor: ... dtype=int64, numpy=1>)\n",
    "     |      ```\n",
    "     |      \n",
    "     |      Args:\n",
    "     |        split: Which split of the data to load (e.g. `'train'`, `'test'`,\n",
    "     |          `['train', 'test']`, `'train[80%:]'`,...). See our\n",
    "     |          [split API guide](https://www.tensorflow.org/datasets/splits).\n",
    "     |          If `None`, will return all splits in a `Dict[Split, tf.data.Dataset]`.\n",
    "     |        batch_size: `int`, batch size. Note that variable-length features will\n",
    "     |          be 0-padded if `batch_size` is set. Users that want more custom behavior\n",
    "     |          should use `batch_size=None` and use the `tf.data` API to construct a\n",
    "     |          custom pipeline. If `batch_size == -1`, will return feature\n",
    "     |          dictionaries of the whole dataset with `tf.Tensor`s instead of a\n",
    "     |          `tf.data.Dataset`.\n",
    "     |        shuffle_files: `bool`, whether to shuffle the input files. Defaults to\n",
    "     |          `False`.\n",
    "     |        decoders: Nested dict of `Decoder` objects which allow to customize the\n",
    "     |          decoding. The structure should match the feature structure, but only\n",
    "     |          customized feature keys need to be present. See\n",
    "     |          [the guide](https://github.com/tensorflow/datasets/tree/master/docs/decode.md)\n",
    "     |          for more info.\n",
    "     |        read_config: `tfds.ReadConfig`, Additional options to configure the\n",
    "     |          input pipeline (e.g. seed, num parallel reads,...).\n",
    "     |        as_supervised: `bool`, if `True`, the returned `tf.data.Dataset`\n",
    "     |          will have a 2-tuple structure `(input, label)` according to\n",
    "     |          `builder.info.supervised_keys`. If `False`, the default,\n",
    "     |          the returned `tf.data.Dataset` will have a dictionary with all the\n",
    "     |          features.\n",
    "     |      \n",
    "     |      Returns:\n",
    "     |        `tf.data.Dataset`, or if `split=None`, `dict<key: tfds.Split, value:\n",
    "     |        tfds.data.Dataset>`.\n",
    "     |      \n",
    "     |        If `batch_size` is -1, will return feature dictionaries containing\n",
    "     |        the entire dataset in `tf.Tensor`s instead of a `tf.data.Dataset`.\n",
    "     |  \n",
    "     |  download_and_prepare(self, *, download_dir=None, download_config=None)\n",
    "     |      Downloads and prepares dataset for reading.\n",
    "     |      \n",
    "     |      Args:\n",
    "     |        download_dir: `str`, directory where downloaded files are stored.\n",
    "     |          Defaults to \"~/tensorflow-datasets/downloads\".\n",
    "     |        download_config: `tfds.download.DownloadConfig`, further configuration for\n",
    "     |          downloading and preparing dataset.\n",
    "     |      \n",
    "     |      Raises:\n",
    "     |        IOError: if there is not enough disk space available.\n",
    "     |  \n",
    "     |  ----------------------------------------------------------------------\n",
    "     |  Readonly properties inherited from tensorflow_datasets.core.dataset_builder.DatasetBuilder:\n",
    "     |  \n",
    "     |  builder_config\n",
    "     |      `tfds.core.BuilderConfig` for this builder.\n",
    "     |  \n",
    "     |  builder_configs\n",
    "     |      classmethod(function) -> method\n",
    "     |      \n",
    "     |      Convert a function to be a class method.\n",
    "     |      \n",
    "     |      A class method receives the class as implicit first argument,\n",
    "     |      just like an instance method receives the instance.\n",
    "     |      To declare a class method, use this idiom:\n",
    "     |      \n",
    "     |        class C:\n",
    "     |            @classmethod\n",
    "     |            def f(cls, arg1, arg2, ...):\n",
    "     |                ...\n",
    "     |      \n",
    "     |      It can be called either on the class (e.g. C.f()) or on an instance\n",
    "     |      (e.g. C().f()).  The instance is ignored except for its class.\n",
    "     |      If a class method is called for a derived class, the derived class\n",
    "     |      object is passed as the implied first argument.\n",
    "     |      \n",
    "     |      Class methods are different than C++ or Java static methods.\n",
    "     |      If you want those, see the staticmethod builtin.\n",
    "     |  \n",
    "     |  canonical_version\n",
    "     |  \n",
    "     |  code_path\n",
    "     |      classmethod(function) -> method\n",
    "     |      \n",
    "     |      Convert a function to be a class method.\n",
    "     |      \n",
    "     |      A class method receives the class as implicit first argument,\n",
    "     |      just like an instance method receives the instance.\n",
    "     |      To declare a class method, use this idiom:\n",
    "     |      \n",
    "     |        class C:\n",
    "     |            @classmethod\n",
    "     |            def f(cls, arg1, arg2, ...):\n",
    "     |                ...\n",
    "     |      \n",
    "     |      It can be called either on the class (e.g. C.f()) or on an instance\n",
    "     |      (e.g. C().f()).  The instance is ignored except for its class.\n",
    "     |      If a class method is called for a derived class, the derived class\n",
    "     |      object is passed as the implied first argument.\n",
    "     |      \n",
    "     |      Class methods are different than C++ or Java static methods.\n",
    "     |      If you want those, see the staticmethod builtin.\n",
    "     |  \n",
    "     |  data_dir\n",
    "     |  \n",
    "     |  data_path\n",
    "     |  \n",
    "     |  info\n",
    "     |      `tfds.core.DatasetInfo` for this builder.\n",
    "     |  \n",
    "     |  release_notes\n",
    "     |  \n",
    "     |  supported_versions\n",
    "     |  \n",
    "     |  url_infos\n",
    "     |      classmethod(function) -> method\n",
    "     |      \n",
    "     |      Convert a function to be a class method.\n",
    "     |      \n",
    "     |      A class method receives the class as implicit first argument,\n",
    "     |      just like an instance method receives the instance.\n",
    "     |      To declare a class method, use this idiom:\n",
    "     |      \n",
    "     |        class C:\n",
    "     |            @classmethod\n",
    "     |            def f(cls, arg1, arg2, ...):\n",
    "     |                ...\n",
    "     |      \n",
    "     |      It can be called either on the class (e.g. C.f()) or on an instance\n",
    "     |      (e.g. C().f()).  The instance is ignored except for its class.\n",
    "     |      If a class method is called for a derived class, the derived class\n",
    "     |      object is passed as the implied first argument.\n",
    "     |      \n",
    "     |      Class methods are different than C++ or Java static methods.\n",
    "     |      If you want those, see the staticmethod builtin.\n",
    "     |  \n",
    "     |  version\n",
    "     |  \n",
    "     |  versions\n",
    "     |      Versions (canonical + availables), in preference order.\n",
    "     |  \n",
    "     |  ----------------------------------------------------------------------\n",
    "     |  Data and other attributes inherited from tensorflow_datasets.core.dataset_builder.DatasetBuilder:\n",
    "     |  \n",
    "     |  BUILDER_CONFIGS = []\n",
    "     |  \n",
    "     |  __annotations__ = {'RELEASE_NOTES': typing.ClassVar[typing.Dict[str, s...\n",
    "     |  \n",
    "     |  ----------------------------------------------------------------------\n",
    "     |  Class methods inherited from tensorflow_datasets.core.registered.RegisteredDataset:\n",
    "     |  \n",
    "     |  __init_subclass__(skip_registration=False, **kwargs) from abc.ABCMeta\n",
    "     |      This method is called when a class is subclassed.\n",
    "     |      \n",
    "     |      The default implementation does nothing. It may be\n",
    "     |      overridden to extend subclasses.\n",
    "     |  \n",
    "     |  ----------------------------------------------------------------------\n",
    "     |  Data descriptors inherited from tensorflow_datasets.core.registered.RegisteredDataset:\n",
    "     |  \n",
    "     |  __dict__\n",
    "     |      dictionary for instance variables (if defined)\n",
    "     |  \n",
    "     |  __weakref__\n",
    "     |      list of weak references to the object (if defined)\n",
    "\n",
    "DATA\n",
    "    CMYK_IMAGES = ['n01739381_1309.JPEG', 'n02077923_14822.JPEG', 'n024473...\n",
    "    PNG_IMAGES = ['n02105855_2933.JPEG']\n",
    "\n",
    "FILE\n",
    "    d:\\programfiles\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_datasets\\image_classification\\imagenet.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
