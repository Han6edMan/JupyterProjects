{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "通常有两种方式保存 tensorflow 模型，即保存检查点或以 SavedModel 格式保存，后者参看[下面的教程](#SavedModel)；\n",
    "\n",
    "检查点**只对模型中的变量（`tf.Variable`对象）进行保存**，而不包含任何模型所定义的函数，进而只能在相应模型的源代码上使用；\n",
    "\n",
    "## 1. 保存检查点\n",
    "### 1.1 Saving from `tf.keras` training APIs\n",
    "`tf.keras.Model.save_weights`可以直接保存检查点，更多细节参见[相关教程](https://www.tensorflow.org/guide/keras/save_and_serialize)\n",
    "\n",
    "### 1.2 手动创建检查点\n",
    "利用`tf.train.Checkpoint`可以手动创建检查点，创建后要检查的对象被设置为该实例的属性；`tf.train.CheckpointManager`则可以帮助管理检查点；训练时通过将网络、优化器、数据集迭代器作为参数传递给`Checkpoint`，利用`ckpt.save`或`manager.save`能够将训练过程的权重保存至检查点；利用`ckpt.restore`或`manager.restore_or_initialize`可以对权重进行恢复；具体可参见下面的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_dataset():\n",
    "    inputs = tf.range(10.)[:, None]\n",
    "    labels = inputs * 5. + tf.range(5.)[None, :]\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(x=inputs, y=labels)).repeat().batch(2)\n",
    "\n",
    "class Net(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(5)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "def train(net, manager, ckpt, restore=True):\n",
    "    # restore or initialize\n",
    "    if manager.latest_checkpoint and restore:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "        ckpt.restore(manager.latest_checkpoint)\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    for epoch in range(50):\n",
    "        example = next(iterator)\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = net(example['x'])\n",
    "            loss = tf.reduce_mean(tf.abs(output - example['y']))\n",
    "        variables = net.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        ckpt.step.assign_add(1)\n",
    "        if int(ckpt.step) % 10 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "            print(\"loss {:1.2f}\".format(loss.numpy()))\n",
    "\n",
    "dataset = toy_dataset()\n",
    "net = Net()\n",
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
    "manager = tf.train.CheckpointManager(ckpt, '../test/Guide/save_a_model/ckpts_net', max_to_keep=3)\n",
    "train_and_checkpoint(net, manager, ckpt, restore=False)\n",
    "print(manager.checkpoints[-1])  # => '../test/Guide/save_a_model/ckpts_net/ckpt-10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面所打印的路径例如`...ckpts_net/ckpt-10`并非磁盘上的文件，而是`index`格式的文件和一个或多个包含了变量值的数据文件的前缀，这些前缀被整合在一个`checkpoint`文件`...ckpts_net/checkpoint`中，其中保存着`CheckpointManager`的状态；`ckpts_net`文件结构如下\n",
    "+ ckpts_net\n",
    "   + checkpoint\n",
    "   + ckpt-8.data-00000-of-00001\n",
    "   + ckpt-8.index\n",
    "   + ckpt-9.data-00000-of-00001\n",
    "   + ckpt-9.index\n",
    "   + ckpt-10.data-00000-of-00001\n",
    "   + ckpt-10.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载机制\n",
    "从被加载的模型对象开始，tensorflow 通过遍历一个带有命名边的有向图，来将变量和检查点进行匹配；边的名称通常由模型属性的名称命名，例如`self.l1 = tf.keras.layers.Dense(5)`中的`l1`；`tf.train.Checkpoint`则使用关键字参数的名称进行命名，例如`tf.train.Checkpoint(step=...)`中的`step`；\n",
    "\n",
    "上面示例的依赖关系图如下所示：\n",
    "<img src=https://tensorflow.org/images/guide/whole_checkpoint.svg width=80%>\n",
    "\n",
    "其中红色节点为优化器，蓝色节点为所有变量，优化器的 slot 变量为橙色，其他节点一律为黑色；slot 变量是优化器状态的一部分，然而是为某个特定的变量而创建的，例如`m`边对应于 Adam 优化器追踪的每个变量动量；只有当变量和优化器都被保存时，slot 变量才会保存在检查点中；\n",
    "\n",
    "对`ckpt.restore`的调用会将需要的恢复操作排到队列中，一旦`Checkpoint`对象中有匹配的路径，便会对变量进行恢复；例如上面定义的模型中，通过重新在网络和`Layer`之间构建一个通向偏置的路径，便可以实现直接对其加载；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_restore = tf.Variable(tf.zeros([5]))\n",
    "fake_layer = tf.train.Checkpoint(bias=to_restore)\n",
    "fake_net = tf.train.Checkpoint(l1=fake_layer)\n",
    "new_ckpt = tf.train.Checkpoint(net=fake_net)\n",
    "status = new_ckpt.restore(tf.train.latest_checkpoint('../test/Guide/save_a_model/ckpts_net'))\n",
    "print(to_restore.numpy())\n",
    "print(\"=\"*64)\n",
    "for k, v in fake_layer.__dict__.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print()\n",
    "print(\"=\"*64)\n",
    "for k, v in fake_net.__dict__.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个例子中依赖关系图为上面依赖关系的子图，入下所示\n",
    "<img src=\"https://tensorflow.org/images/guide/partial_checkpoint.svg\">\n",
    "\n",
    "`restore`返回一个状态对象，该对象具有 assertions；所有在新检查点创建的变量都已经被恢复，so `status.assert_existing_objects_matched` passes.\n",
    "```python\n",
    "status.assert_existing_objects_matched()\n",
    "```\n",
    "检查点中有许多对象没有进行匹配，例如一个层的权重和优化器的变量；`status.assert_consume`只有在检查点和程序完全匹配时才通过，并在这里抛出异常；（？）\n",
    "\n",
    "\n",
    "### 2.1 延迟恢复\n",
    "当可以获得输入形状时，`Layer`对象在第一次调用变量时可能会延迟对其的创建；例如`Dense`层的权重的形状依赖于该层的输入和输出，因此提供给构造函数输出形状并不足以创建这个权重变量；由于调用`Layer`需要读取该权重的值，进而对变量的恢复发生在变量创建之后、变量使用之前；例如下面的例子，`tf.train.Checkpoint`队列对没有匹配变量的队列进行匹配；\n",
    "```python\n",
    "delayed_restore = tf.Variable(tf.zeros([1, 5]))\n",
    "print(delayed_restore.numpy())  # Not restored; still zeros\n",
    "fake_layer.kernel = delayed_restore\n",
    "print(delayed_restore.numpy())  # Restored\n",
    "```\n",
    "\n",
    "\n",
    "### 2.2 对检查点进行检查\n",
    "`tf.train.load_checkpoint`返回一个`CheckpointReader`，它可以提供对检查点内容的低级访问，并包含了从每个变量的键到对应形状和数据类型的映射；需要注意的是，检查点没有更高级的结构，其只含有变量和路径的信息，没有模型、层以及层与层之间如何连接的信息；可参见如下示例；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = tf.train.load_checkpoint('../test/Guide/save_a_model/ckpts_net')\n",
    "shape_from_key = reader.get_variable_to_shape_map()\n",
    "dtype_from_key = reader.get_variable_to_dtype_map()\n",
    "key = next(iter(shape_from_key.keys()))\n",
    "print(\"value:\", reader.get_tensor(key), \"\\nshape:\", shape_from_key[key], \"\\ndtype:\", dtype_from_key[key].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 对列表和字典的追踪\n",
    "`Checkpoint`也会对分配给其属性的列表和字典进行追踪；\n",
    "```python\n",
    "save = tf.train.Checkpoint()\n",
    "save.listed = [tf.Variable(1.), tf.Variable(2.)]\n",
    "save.mapped = {'one': save.listed[0], 'two': save.listed[1]}\n",
    "save_path = save.save('./tf_list_example')\n",
    "\n",
    "restore = tf.train.Checkpoint()\n",
    "v2 = tf.Variable(0.)\n",
    "assert 0. == v2.numpy()  # Not restored yet\n",
    "restore.mapped = {'two': v2}\n",
    "restore.restore(save_path)\n",
    "assert 2. == v2.numpy()\n",
    "```\n",
    "用户可能会注意到用于列表和字典的包装对象，这些包装器是底层数据结构的检查点版本，与基于属性的加载类似，这些包装器在变量被添加到列表或字典时就对其进行恢复；\n",
    "```python\n",
    "restore.listed = []\n",
    "print(restore.listed)  # => ListWrapper([])\n",
    "v1 = tf.Variable(0.)\n",
    "restore.listed.append(v1)\n",
    "assert 1. == v1.numpy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SavedModel\n",
    "SavedModel 包含了对模型中定义的计算的序列化描述，即可训练参数和计算图，或者说完整的 tensorflow 程序，其不需要运行模型搭建的代码，进而有利于在 [TFLite](https://www.tensorflow.org/lite), [TensorFlow.js](https://www.tensorflow.org/js/), [TensorFlow Serving](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple), [TensorFlow Hub](https://www.tensorflow.org/hub) 上部署和共享；可以使用以下 API 对模型以 SavedModel 格式进行保存和加载：\n",
    "- low-level 的`tf.saved_model`，此 API 会在下面详细说明\n",
    "    - 模型保存：`tf.saved_model.save(model, path_to_dir)`\n",
    "    - 模型加载：`model = tf.saved_model.load(path_to_dir)`\n",
    "\n",
    "- high-level 的`tf.keras.Model`，参见 keras 保存与序列化教程 [here](https://www.tensorflow.org/guide/keras/save_and_serialize)\n",
    "\n",
    "- 只需要对模型的权重进行加载和保存，可参见[上面的教程](#Checkpoint)\n",
    "\n",
    "\n",
    "\n",
    "## 1. Creating a SavedModel from Keras\n",
    "为能够快速上手，本节先示范如何导出一个预训练的 Keras 模型，并将其用于图像分类的任务上；创建 SavedModels 的其他方法会在后面详细讨论；\n",
    "\n",
    "首先下载一个图片作为范例：\n",
    "```python\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "file = tf.keras.utils.get_file(\n",
    "    \"grace_hopper.jpg\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\"\n",
    ")\n",
    "img = Image.open(file).resize((224, 224))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<center>\n",
    "    <img src=../img/Guide/Save_a_model/grace_hopper.jpg width=20%>\n",
    "</center>\n",
    "\n",
    "接着导入预训练的模型，如 MobileNet，并对图片进行分类：\n",
    "```python\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "labels_path = tf.keras.utils.get_file(\n",
    "    'ImageNetLabels.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "labels = np.array(open(labels_path).read().splitlines())\n",
    "model = tf.keras.applications.MobileNet()\n",
    "out = model(x[np.newaxis])\n",
    "pred = labels[np.argsort(out)[0,::-1][:5]+1]\n",
    "# ==> ['pillow' 'balloon' 'prayer rug' 'parachute' 'coral reef']\n",
    "```\n",
    "\n",
    "再对模型进行保存：\n",
    "```python\n",
    "mobilenet_save_path = os.path.join(tmp_dir, \"mobilenet/1/\")\n",
    "tf.saved_model.save(model, mobilenet_save_path)\n",
    "```\n",
    "这里保存路径遵循了 TF Serving 所使用的惯例，即路径中最后的部分表示模型的版本号，即代码中的`1/`，进而 TF Serving 可以根据其来推断不同模型之间的更新关系；\n",
    "\n",
    "利用`tf.saved_model.load`加载模型：\n",
    "```python\n",
    "loaded = tf.saved_model.load(mobilenet_save_path)\n",
    "list(loaded.signatures.keys())  # ==> [\"serving_default\"]\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)\n",
    "\"\"\" ==>\n",
    "{'predictions': TensorSpec(shape=(None, 1000), dtype=tf.float32, name='predictions')}\n",
    "\"\"\"\n",
    "```\n",
    "导入的 signature 总会以字典形式返回，若要自定义 signature 名称和字典键值；在导出模型时指定 signature 的教程可参见 [here](#4.-Specifying-signatures-during-export)；\n",
    "\n",
    "将模型用于推断：\n",
    "```python\n",
    "labeling = infer(tf.constant(x))[model.output_names[0]]\n",
    "decoded = labels[np.argsort(labeling)[0,::-1][:5]+1]\n",
    "# ==> ['pillow' 'balloon' 'prayer rug' 'parachute' 'coral reef']\n",
    "```\n",
    "\n",
    "## 2. Saving a custom model\n",
    "`tf.saved_model.save`支持对`tf.Module`及其子类进行保存，例如`tf.keras.Layer`、`tf.keras.Model`；\n",
    "\n",
    "在对`tf.Module`进行保存时，所有`tf.Variable`的属性、[`tf.function`](https://www.tensorflow.org/api_docs/python/tf/function)修饰的方法、通过递归遍历的`tf.Module`均会被保存，而任何 Python 属性、函数、数据均会丢失，即保存`tf.function`时不会保存任何 Python 代码；然而，由于`tf.function`通过跟踪 Python 代码来生成一个`ConcreteFunction`，这是一个包装了`tf.Graph`可调用对象，进而保存`tf.function`实际上是保存了`tf.function`的`ConcreteFunction`缓存；更多关于`tf.function`和`ConcreteFunction`的关系可参见相关教程 [here](https://www.tensorflow.org/guide/function)；\n",
    "\n",
    "以下是对`tf.Module`保存和复原的例子：\n",
    "\n",
    "```python\n",
    "class CustomModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModule, self).__init__()\n",
    "        self.v = tf.Variable(1.)\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        print('Tracing with', x)\n",
    "        return x * self.v\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "    def mutate(self, new_v):\n",
    "        self.v.assign(new_v)\n",
    "\n",
    "module = CustomModule()(tf.constant(3.))\n",
    "module_no_sig_path = os.path.join(tmpdir, 'custom_module')\n",
    "tf.saved_model.save(module, module_no_sig_path)\n",
    "\"\"\" ==>\n",
    "    Tracing with Tensor(\"x:0\", shape=(), dtype=float32)\n",
    "    Tracing with Tensor(\"x:0\", shape=(), dtype=float32)\n",
    "    INFO:tensorflow:Assets written to: .../custom_module/assets\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "## 3. Loading and using a custom model\n",
    "在 Python 中加载 SavedModel 时，所有的`tf.Variable`属性、`tf.function`修饰的方法、`tf.Modules`会被恢复到与之前保存的`tf.Module`相同的对象结构中；\n",
    "\n",
    "```python\n",
    "module_no_sig = tf.saved_model.load(module_no_sig_path)\n",
    "assert module_no_sig(tf.constant(3.)).numpy() == 3\n",
    "module_no_sig.mutate(tf.constant(2.))\n",
    "assert module_no_sig(tf.constant(3.)).numpy() == 6\n",
    "```\n",
    "由于保存过程中并未保存代码，进而使用新的输入 signature 调用`tf.function`会报错\n",
    "\n",
    "```python\n",
    "module_no_sig(tf.constant([3.]))\n",
    "\"\"\" ==>\n",
    "ValueError: Could not find matching function to call for canonicalized inputs ((,), {}). Only existing signatures are [((TensorSpec(shape=(), dtype=tf.float32, name=u'x'),), {})].\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 3.1 Basic fine-tuning\n",
    "\n",
    "但由于`Variable`对象是可用的，进而可以通过导入的函数来进行反向传播，这足以在简单情况下对 SavedModel 进行微调\n",
    "\n",
    "```python\n",
    "optimizer = tf.optimizers.SGD(0.05)\n",
    "\n",
    "def train_step():\n",
    "     with tf.GradientTape() as tape:\n",
    "        loss = (10. - module_no_sig(tf.constant(2.))) ** 2\n",
    "    variables = tape.watched_variables()\n",
    "    grads = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(grads, variables))\n",
    "    return loss\n",
    "\n",
    "for _ in range(10):\n",
    "    # `v` will approach 5, `loss` will approach 0\n",
    "    print(\"loss={:.2f} v={:.2f}\".format(\n",
    "        train_step(), module_no_sig.v.numpy()\n",
    "    ))\n",
    "\"\"\" ==>\n",
    "loss=36.00 v=3.20\n",
    "loss=12.96 v=3.92\n",
    "loss=4.67 v=4.35\n",
    "loss=1.68 v=4.61\n",
    "loss=0.60 v=4.77\n",
    "loss=0.22 v=4.86\n",
    "loss=0.08 v=4.92\n",
    "loss=0.03 v=4.95\n",
    "loss=0.01 v=4.97\n",
    "loss=0.00 v=4.98\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 3.2 General fine-tuning\n",
    "除`__call__`外，Keras 中的 SavedModel 提供了更多功能来应对更复杂的微调需求，TF Hub建议，如果适用的话，可以在 SavedModels 中提供以下内容，以便进行微调：\n",
    "\n",
    "- 若模型使用了 dropout 或其他在训练和推断阶段前向传播计算不同的技术，例如 BN，可以通过设定`__call__`方法的参数`training=True`来实现\n",
    "\n",
    "- 可以通过设置`.variable`和`.trainable_variable`属性来决定哪些变量是可训练的而哪些是不可训练的\n",
    "\n",
    "- 对于类似 Keras 这样将权重正则化作为一个层或子模型的属性的框架，`.regularization_losses`属性，其包括了一个零参数的函数列表，这些函数的输出值会添加到总损失中\n",
    "\n",
    "## 4. Specifying signatures during export\n",
    "类似 TF Serving 和`saved_model_cli`这样的工具可以与 SavedModel 进行交互；为了使其确定要使用哪些`ConcreteFunctions`，用户需要指定 serving signature；尽管`tf.keras.Model`会自动指定  serving signature，但由于自定义`tf.Module`模块默认情况下不声明 signature，进而必须通过对`ConcreteFunctions`提供`signatures`关键参数来显示地对其声明；当只声明一个 signature 时，其键值默认为`'serving_default'`，这个键以常数`tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY`保存；\n",
    "```python\n",
    "module_sig_path = os.path.join(tmpdir, 'module_with_sig')\n",
    "sig = module.__call__.get_concrete_function(\n",
    "    tf.TensorSpec(None, tf.float32)\n",
    ")\n",
    "tf.saved_model.save(module, module_sig_path, signatures=sig)\n",
    "module_sig = tf.saved_model.load(module_sig_path)\n",
    "list(module_sig.signatures.keys())  # ==> ['serving_default']\n",
    "```\n",
    "\n",
    "要导出多个 signatures，则需要传递一个含有 signatures 键值的字典，每一个键与一个`ConcreteFunction`相关联\n",
    "```python\n",
    "module_multi_sigs_path = os.path.join(tmpdir, 'module_multi_sigs')\n",
    "sigs = {\"serving_default\": call,\n",
    "        \"array_input\": module.__call__.get_concrete_function(\n",
    "            tf.TensorSpec([None], tf.float32)\n",
    "        )}\n",
    "tf.saved_model.save(module, module_multi_sig_path, signatures=sigs)\n",
    "module_multi_sigs = tf.saved_model.load(module_multi_sigs_path)\n",
    "list(module_multi_sigs.signatures.keys())\n",
    "# ==> ['serving_default', 'array_input']\n",
    "```\n",
    "默认情况下，输出张量名称是相当通用的，例如`output_0`；若需要改变输出的名称，则需要修改`tf.function`以使其返回一个字典，该字典用于将输出名称映射到输出变量；输入名称则来自 Python 函数的参数名称；\n",
    "\n",
    "```python\n",
    "\n",
    "class CustomModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModule, self).__init__()\n",
    "        self.v = tf.Variable(1.)\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "    def __call__(self, x):\n",
    "        return {'custom_output_name': x * self.v}\n",
    "\n",
    "module = CustomModule()\n",
    "call_output = module_output.__call__.get_concrete_function(\n",
    "    tf.TensorSpec(None, tf.float32)\n",
    ")\n",
    "module_path = os.path.join(tmpdir, 'module_with_output_name')\n",
    "tf.saved_model.save(module_output, module_output_path,\n",
    "                    signatures={'serving_default': call_output})\n",
    "module_with_output_name = tf.saved_model.load(module_path)\n",
    "module_with_output_name.signatures['serving_default'].structured_outputs\n",
    "\"\"\" ==>\n",
    "{'custom_output_name': TensorSpec(shape=(), dtype=tf.float32, name='custom_output_name')}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "## 5. The SavedModel format on disk\n",
    "SavedModel 是一个包含了序列化的 signature 和运行它们所需的状态的目录，其包括了变量值和 vocabularies：\n",
    "```bash\n",
    "ls {mobilenet_save_path}  # ==> assets  saved_model.pb  variables\n",
    "```\n",
    "\n",
    "其中`assets`目录包含了 TF 计算图使用的文件，例如用于初始化 vocabulary 表格的文本文件；`saved_model.pb`文件保存了 TF 程序，即所搭建的模型，以及一系列被命名的 signature，每个 signatures 代表着一个接收张量输入并返回张量输出的函数；`variables`目录下一个标准的训练检查点\n",
    "```bash\n",
    "ls {mobilenet_save_path}/variables\n",
    "# ==> variables.data-00000-of-00001  variables.index\n",
    "```\n",
    "此外，对于 SavedModel 而言，也可能包含`assets.extra`目录，其中包含了不为 TF 计算图使用的文件，例如怎样使用 SavedModel 的信息，而 TF 本身并不含有此目录；\n",
    "\n",
    "SavedModels 可能包含模型的多个变体，例如多种`v1.MetaGraphDefs`、用`--tag_set`标识的`saved_model_cli`模型，但这种情况很少见；创建模型的多个变体的 API 包括`tf.Estimator.experimental_export_all_saved_models`和 TF1 中的`tf.saved_model.Builder`\n",
    "\n",
    "```bash\n",
    "saved_model_cli show --dir {mobilenet_save_path} --tag_set serve\n",
    "```\n",
    "\n",
    "## 6. [Running a SavedModel in TensorFlow Serving](https://www.tensorflow.org/guide/saved_model)\n",
    "\n",
    "端到端的 TF-serving 实例可参见 [here](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Details of the SavedModel command line interface\n",
    "利用 SavedModel Command Line (CLI) 可以对 SavedModel 进行检查和执行，例如通过 CLI 检查模型的`SignatureDefs`，利用 CLI 也可以迅速确认输入张量的数据类型和形状是否与模型匹配；此外，若需要对模型进行测试，可以使用 CLI 传入多种格式的输入 (例如 Python 表达式) 再获取输出，进而对模型进行完整性检查；\n",
    "\n",
    "### 7.1 Install the SavedModel CLI\n",
    "一般而言，用户可以通过安装一个预编译的 TensorFlow 二进制文件，或利用源代码搭建来安装 TensorFlow；若安装方式为前者，则 SavedModel CLI 已经被安装在了`bin/saved_model_cli`目录下，若安装方式为后者，则需要运行以下代码来构建\n",
    "```bash\n",
    "bazel build tensorflow/python/tools:saved_model_cli\n",
    "```\n",
    "\n",
    "### 7.2 Commands\n",
    "SavedModel CLI 支持以下两种命令行：\n",
    "- `show`: 显示 SavedModel 中可用的计算\n",
    "- `run`：运行 SavedModel 中的计算\n",
    "\n",
    "#### 7.2.1 show command\n",
    "SavedModel 包含一个或多个模型变体，这些模型由它们的标签集 (tag-set) 标识；to serve a model，需要知道每个模型变体中的`SignatureDef`类型及其输入与输出；`show`命令行可以按层级顺序检查 SavedModel 的内容，语法如下\n",
    "```bash\n",
    "usage: saved_model_cli show [-h] --dir DIR [--all]\n",
    "[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n",
    "```\n",
    "例如下面的命令行显示了 SavedModel 中所有可用的标记集：\n",
    "```bash\n",
    "saved_model_cli show --dir /tmp/saved_model_dir\n",
    "\"\n",
    "The given SavedModel contains the following tag-sets:\n",
    "serve\n",
    "serve, gpu\n",
    "\"\n",
    "```\n",
    "为`--tag_set`提供参数可以显示一个标签集的所有可用`SignatureDef`键，若一个标签集中有多个标签，则须指定所有标签，每个标签用逗号分隔；若要显示特定`SignatureDef`的所有输入和输出的张量信息，则需要将`SignatureDef`键传递给`signature_def`选项；这对于获取张量键值、输入张量的数据类型和形状很有帮助；若要显示 SavedModel 中的所有可用信息，可使用`--all`选项：\n",
    "```bash\n",
    "saved_model_cli show --dir /tmp/saved_model_dir --all\n",
    "\"\n",
    "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
    "\n",
    "signature_def['classify_x2_to_y3']:\n",
    "  The given SavedModel SignatureDef contains the following input(s):\n",
    "    inputs['inputs'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: x2:0\n",
    "  The given SavedModel SignatureDef contains the following output(s):\n",
    "    outputs['scores'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: y3:0\n",
    "  Method name is: tensorflow/serving/classify\n",
    "\n",
    "...\n",
    "\n",
    "signature_def['serving_default']:\n",
    "  The given SavedModel SignatureDef contains the following input(s):\n",
    "    inputs['x'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: x:0\n",
    "  The given SavedModel SignatureDef contains the following output(s):\n",
    "    outputs['y'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: y:0\n",
    "  Method name is: tensorflow/serving/predict\n",
    "\"\n",
    "```\n",
    "\n",
    "#### 7.2.2 run command\n",
    "```bash\n",
    "saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n",
    "                       SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
    "                       [--input_exprs INPUT_EXPRS]\n",
    "                       [--input_examples INPUT_EXAMPLES]\n",
    "                       [--outdir OUTDIR] [--overwrite] [--tf_debug]\n",
    "```\n",
    "\n",
    "调用`run`命令可以运行计算图，传递输入，显示输出，并在需要时对输出进行保存；\n",
    "\n",
    "**Args**\n",
    "\n",
    "- `--inputs`: 用于传递含有文件中的数据；`INPUTS`的语法格式为`<input_key>=<filename>`或`<input_key>=<filename>[<variable_name>]`，当传递多个`INPUTS`时，不同`INPUTS`之间用分号隔开；由于`saved_model_cli`使用`numpy.load`加载`filename`，故`filename`格式应为\n",
    "    - `.npy`：由于`.npy`文件总含有一个 Numpy 数组，进而在加载`.npy`文件时，其所含数组会直接分配给指定的输入张量；当对`.npy`指明`variable_name`时，`variable_name`会被忽略，同时发出一个`warning`\n",
    "    - `.npz`：利用`.npz`文件加载时，可以指定`variable_name`来作为输入张量的键值，以标识压缩文件中要加载的变量；如果不指定`variable_name`，SavedModel CLI 则会检查压缩文件中是否只包含一个文件，并为根据的输入张量的键加载该文件；\n",
    "    - pickle 文件：当从 pickle 文件加载时，如果没有指定`variable_name`，那么 pickle 文件中的所有内容都将传递给指定的输入张量键；否则 SavedModel CLI 会假定 dictionary 存储在 pickle 文件中，并使用与`variable_name`对应的值加载数据\n",
    "- `--input_exprs`：在没有现成数据文件时，若仍然希望对模型进行全面的检查时，可以利用此选项传递 Python 表达式，以生成一些与模型的`SignatureDef`的数据类型和形状匹配的简单输入；例如`<input_key>=[[1],[2],[3]]`或`<input_key>=np.ones((32,32,3))`\n",
    "- `--input_examples`：用于传递`tf.train.Example`；`input_key`应为由字典组成的列表，其中每个字典均为`tf.train.Example`的实例，字典的键代表特征，字典的值为每个特征所取的值组成的列表，如`<input_key>=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n",
    "- `--outdir`：默认情况下，SavedModel CLI 会将输出写入`stdout`中，通过给`--outdir`传递目标路径，可以将输出以`.npy`文件的形式保存在给定路径下，文件中张量以输出键值作为键索引；\n",
    "- `--overwrite`：用于重写已经存在的输出文件\n",
    "\n",
    "## [8. Load a SavedModel in C++](https://www.tensorflow.org/guide/saved_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
