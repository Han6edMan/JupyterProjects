{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.losses as losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow.keras.losses\n",
    "\n",
    "包含了内置的损失函数的模块，该模块引入时需`import keras.losses as ...`，或可以直接以`tf.losses.x`形式调用\n",
    "\n",
    "**Classes**\n",
    "- BinaryCrossentropy\n",
    "- CategoricalCrossentropy\n",
    "- CategoricalHinge\n",
    "- CosineSimilarity\n",
    "- Hinge\n",
    "- Huber\n",
    "- KLD\n",
    "- KLDivergence\n",
    "- LogCosh\n",
    "- Loss\n",
    "- MAE\n",
    "- MAPE\n",
    "- MSE\n",
    "- MSLE\n",
    "- MeanAbsoluteError\n",
    "- MeanAbsolutePercentageError\n",
    "- MeanSquaredError\n",
    "- MeanSquaredLogarithmicError\n",
    "- Poisson\n",
    "- Reduction\n",
    "- SparseCategoricalCrossentropy\n",
    "- SquaredHinge\n",
    "\n",
    "**Functions**\n",
    "\n",
    "- binary_crossentropy\n",
    "- categorical_crossentropy\n",
    "- categorical_hinge\n",
    "- cosine_similarity\n",
    "- deserialize\n",
    "- get\n",
    "- hinge\n",
    "- kld\n",
    "- kullback_leibler_divergence\n",
    "- logcosh\n",
    "- mae\n",
    "- mape\n",
    "- mean_absolute_error\n",
    "- mean_absolute_percentage_error\n",
    "- mean_squared_error\n",
    "- mean_squared_logarithmic_error\n",
    "- mse\n",
    "- msle\n",
    "- poisson\n",
    "- serialize\n",
    "- sparse_categorical_crossentropy\n",
    "- squared_hinge\n",
    "\n",
    "**FILE**： tensorflow\\keras\\losses\\\\\\_\\_init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# losses.SparseCategoricalCrossentropy()\n",
    "```python\n",
    "losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction='auto',\n",
    "    name='sparse_categorical_crossentropy',\n",
    ")\n",
    "```\n",
    "\n",
    "**Docstring**:\n",
    "\n",
    "Computes the crossentropy loss between the labels and predictions.\n",
    "\n",
    "Use this crossentropy loss function when there are two or more label classes.\n",
    "We expect labels to be provided as integers. If you want to provide labels\n",
    "using `one-hot` representation, please use `CategoricalCrossentropy` loss.\n",
    "There should be `# classes` floating point values per feature for `y_pred`\n",
    "and a single floating point value per feature for `y_true`.\n",
    "\n",
    "In the snippet below, there is a single floating point value per example for\n",
    "`y_true` and `# classes` floating pointing values per example for `y_pred`.\n",
    "The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n",
    "`[batch_size, num_classes]`.\n",
    "\n",
    "**Args**:\n",
    "- from_logits: Whether `y_pred` is expected to be a logits tensor. By default, we assume that `y_pred` encodes a probability distribution. Note - Using from_logits=True may be more numerically stable.\n",
    "\n",
    "- reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to loss. Default value is `AUTO`. `AUTO` indicates that the reduction option will be determined by the usage context. For almost all cases this defaults to `SUM_OVER_BATCH_SIZE`. When used with `tf.distribute.Strategy`, outside of built-in training loops such as `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE` will raise an error. Please see this custom training [tutorial](https://www.tensorflow.org/tutorials/distribute/custom_training)\n",
    "for more details.\n",
    "\n",
    "- name: 操作的名称，默认 'sparse_categorical_crossentropy'\n",
    " \n",
    "Usage:\n",
    "\n",
    ">>> y_true = [1, 2]\n",
    ">>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    ">>> # Using 'auto'/'sum_over_batch_size' reduction type.\n",
    ">>> scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ">>> scce(y_true, y_pred).numpy()\n",
    "1.177\n",
    "\n",
    ">>> # Calling with 'sample_weight'.\n",
    ">>> scce(y_true, y_pred, sample_weight=tf.constant([0.3, 0.7])).numpy()\n",
    "0.814\n",
    "\n",
    ">>> # Using 'sum' reduction type.\n",
    ">>> scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "...     reduction=tf.keras.losses.Reduction.SUM)\n",
    ">>> scce(y_true, y_pred).numpy()\n",
    "2.354\n",
    "\n",
    ">>> # Using 'none' reduction type.\n",
    ">>> scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "...     reduction=tf.keras.losses.Reduction.NONE)\n",
    ">>> scce(y_true, y_pred).numpy()\n",
    "array([0.0513, 2.303], dtype=float32)\n",
    "\n",
    "Usage with the `compile` API:\n",
    "\n",
    "```python\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile('sgd', loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "```\n",
    "Init docstring:\n",
    "Initializes `SparseCategoricalCrossentropy` instance.\n",
    "\n",
    "\n",
    "File:           d:\\programfiles\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\n",
    "Type:           type\n",
    "Subclasses:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# losses.categorical_crossentropy()\n",
    "```python\n",
    "losses.categorical_crossentropy(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    from_logits=False,\n",
    "    label_smoothing=0,\n",
    ")\n",
    "```\n",
    "\n",
    "**Args**:\n",
    "\n",
    "- y_true: 独热码形式的真值\n",
    "- y_pred: 预测值\n",
    "- from_logits: `y_pred`是否为 logits 张量，默认情况下假设`y_pred`各元素服从一个概率分布\n",
    "- label_smoothing: 应为 [0, 1] 区间的浮点数，若大于零则对标签进行平滑处理\n",
    "\n",
    "**File**:   \\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\n",
    "\n",
    "**Type**:      function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryCrossentropy\n",
      "CategoricalCrossentropy\n",
      "CategoricalHinge\n",
      "CosineSimilarity\n",
      "Hinge\n",
      "Huber\n",
      "KLD\n",
      "KLDivergence\n",
      "LogCosh\n",
      "Loss\n",
      "MAE\n",
      "MAPE\n",
      "MSE\n",
      "MSLE\n",
      "MeanAbsoluteError\n",
      "MeanAbsolutePercentageError\n",
      "MeanSquaredError\n",
      "MeanSquaredLogarithmicError\n",
      "Poisson\n",
      "Reduction\n",
      "SparseCategoricalCrossentropy\n",
      "SquaredHinge\n",
      "binary_crossentropy\n",
      "categorical_crossentropy\n",
      "categorical_hinge\n",
      "cosine_similarity\n",
      "deserialize\n",
      "get\n",
      "hinge\n",
      "kld\n",
      "kullback_leibler_divergence\n",
      "logcosh\n",
      "mae\n",
      "mape\n",
      "mean_absolute_error\n",
      "mean_absolute_percentage_error\n",
      "mean_squared_error\n",
      "mean_squared_logarithmic_error\n",
      "mse\n",
      "msle\n",
      "poisson\n",
      "serialize\n",
      "sparse_categorical_crossentropy\n",
      "squared_hinge\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(losses.__dict__.items()):\n",
    "    if callable(v):\n",
    "        print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
