{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow.keras\n",
    "\n",
    "Implementation of the Keras API meant to be a high-level API for TensorFlow.\n",
    "\n",
    "**DESCRIPTION**\n",
    "\n",
    "TensorFlow 内置的 Keras API 实现库，帮助文档参见[tensorflow.org](https://www.tensorflow.org/guide/keras).\n",
    "\n",
    "**PACKAGE CONTENTS**\n",
    "\n",
    "    activations (package)\n",
    "    applications (package)\n",
    "    backend (package)\n",
    "    callbacks (package)\n",
    "    constraints (package)\n",
    "    datasets (package)\n",
    "    estimator (package)\n",
    "    experimental (package)\n",
    "    initializers (package)\n",
    "    layers (package)\n",
    "    losses (package)\n",
    "    metrics (package)\n",
    "    mixed_precision (package)\n",
    "    models (package)\n",
    "    optimizers (package)\n",
    "    premade (package)\n",
    "    preprocessing (package)\n",
    "    regularizers (package)\n",
    "    utils (package)\n",
    "    wrappers (package)\n",
    "\n",
    "**FUNCTIONS**\n",
    "\n",
    "- Input\n",
    "\n",
    "**CLASSES**\n",
    "\n",
    "- Sequential\n",
    "\n",
    "- Model\n",
    "\n",
    "**FILE**：  \\tensorflow\\lib\\site-packages\\tensorflow\\keras\\\\\\_\\_init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras.Input()\n",
    "```python\n",
    "keras.Input(\n",
    "    shape=None,\n",
    "    batch_size=None,\n",
    "    name=None,\n",
    "    dtype=None,\n",
    "    sparse=False,\n",
    "    tensor=None,\n",
    "    ragged=False,\n",
    "    **kwargs,\n",
    ")\n",
    "```\n",
    "`Input()`用于初始化一个 Keras 符号张量，可以起到一个占位符的效果；需要注意的是，即使在即时执行模式下，该占位符仍旧可以参与 TF 运算并即时输出结果，但输出的张量依然没有具体取值，而仅仅是对张量形状的匹配性进行运算；\n",
    "\n",
    "**Args**\n",
    "- shape: 可以是整数构成的元祖、整数构成的列表、`TensorShape`实例，其不包含 batch 维度；若某一维度是 None，则代表该维度的形状未知待定；`shape`和`tensor`均为 None 时会抛出`ValueError`异常；\n",
    "- batch_size, dtype: pass;\n",
    "- name: 该层的名称；\n",
    "- sparse: 用于指明这个占位符是否为稀疏张量；`ragged`和`sparse`只能有一个为真，否则会抛出`ValueError`异常；\n",
    "- tensor: 初始化`Input`层的张量；为其指明具体值时，该层便不再起占位符的作用；`shape`和`tensor`均为 None 时会抛出`ValueError`异常；\n",
    "- ragged: 用于指明这个占位符是否为不规则张量；`ragged`和`sparse`只能有一个为真，否则会抛出`ValueError`异常；`ragged`为 True 时，`shape`中指明了 None 的维度表示那个不规则的维度；更多有关不规则张量的信息参见[相关教程](https://www.tensorflow.org/guide/ragged_tensors)；\n",
    "- \\*\\*kwargs: 对弃用参数提供支持，例如`batch_shape`、`batch_input_shape`等，当同时指明`shape`和`batch_input_shape`、或`shape`和`batch_shape`时会抛出`ValueError`异常；\n",
    "\n",
    "**File**:  \\keras\\engine\\input_layer.py\n",
    "\n",
    "**Type**:      function\n",
    "\n",
    "### Example\n",
    "简单的使用：\n",
    "```python\n",
    "inputs = Input(shape=(64,))\n",
    "x = Dense(32, activation='relu')(inputs)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "outputs = Dense(10, activation='relu')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "即时执行模式下，占位符参与 TF 运算的结果没有具体取值\n",
    "```python\n",
    "x0 = keras.Input(shape=(1, 32))\n",
    "x1 = keras.Input(shape=(32, 4))\n",
    "y = x0 @ x1\n",
    "y.shape  # ==> TensorShape([None, 1, 4])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras.Sequential()\n",
    "`keras.Sequential(layers=None, name=None, *args, **kwargs)`\n",
    "\n",
    "**Docstring**:\n",
    "\n",
    "`Sequential`将若干线性堆叠的层 group into `tf.keras.Model`，并为该模块提供训练和推断的特性\n",
    "\n",
    "**Args**:\n",
    "\n",
    "- layers: 添加到该模型的层所组成的列表\n",
    "- name: 该模型的名称\n",
    "\n",
    "**File**:  tensorflow\\python\\keras\\engine\\sequential.py\n",
    "\n",
    "**Type**:           type\n",
    "\n",
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # Optionally, the first layer can receive an `input_shape` argument:\n",
    ">>> model = keras.Sequential()\n",
    ">>> model.add(layers.Dense(8, input_shape=(16,)))\n",
    ">>> # Afterwards, we do automatic shape inference:\n",
    ">>> model.add(layers.Dense(4))\n",
    "\n",
    ">>> # This is identical to the following:\n",
    ">>> model = keras.Sequential()\n",
    ">>> model.add(layers.Dense(8, input_dim=16))\n",
    "\n",
    ">>> # And to the following:\n",
    ">>> model = keras.Sequential()\n",
    ">>> model.add(layers.Dense(8, batch_input_shape=(None, 16)))\n",
    "\n",
    "\n",
    "\n",
    ">>> # When using the delayed-build pattern (no input shape specified), you can\n",
    ">>> # choose to manually build your model by calling\n",
    ">>> # `build(batch_input_shape)`:\n",
    ">>> model = keras.Sequential()\n",
    ">>> model.add(layers.Dense(8))\n",
    ">>> model.add(layers.Dense(4))\n",
    ">>> model.build((None, 16))\n",
    ">>> len(model.weights)\n",
    "4\n",
    "\n",
    "\n",
    "# Note that when using the delayed-build pattern (no input shape specified),\n",
    "# the model gets built the first time you call `fit` (or other training and\n",
    "# evaluation methods).\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(8))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "# This builds the model for the first time:\n",
    "model.fit(x, y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras.Sequential().add()\n",
    "`model.add(layer)`\n",
    "\n",
    "在已有的网络层下面(由输入指向输出的方向为下)添加一个`layer`；当添加的`layer`无法获得其输入形状时，或有多个输出张量时，或已经与其他模块相连接时，会抛出`ValueError`异常\n",
    "\n",
    "**Type**:      function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras.Sequential.pop()\n",
    "`model.pop()`\n",
    "\n",
    "删除模型中的最后一层\n",
    "\n",
    "**Type**:      function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    layers\n",
    "    <property object at 0x00000138AD8C4720>\n",
    "\n",
    "    dynamic\n",
    "    <property object at 0x00000138A8BF6310>\n",
    "\n",
    "    add\n",
    "    <function Sequential.add at 0x00000138BBCEF310>\n",
    "\n",
    "    pop\n",
    "    <function Sequential.pop at 0x00000138BBCEF430>\n",
    "\n",
    "    build\n",
    "    <function Sequential.build at 0x00000138BBCEF4C0>\n",
    "\n",
    "    call\n",
    "    <function Sequential.call at 0x00000138BBCEF550>\n",
    "\n",
    "    compute_output_shape\n",
    "    <function Sequential.compute_output_shape at 0x00000138BBCEF5E0>\n",
    "\n",
    "    compute_mask\n",
    "    <function Sequential.compute_mask at 0x00000138BBCEF670>\n",
    "\n",
    "    predict_proba\n",
    "    <function Sequential.predict_proba at 0x00000138BBCEF820>\n",
    "\n",
    "    predict_classes\n",
    "    <function Sequential.predict_classes at 0x00000138BBCEF940>\n",
    "\n",
    "    get_config\n",
    "    <function Sequential.get_config at 0x00000138BBCEF700>\n",
    "\n",
    "    from_config\n",
    "    <classmethod object at 0x00000138BBCE5F40>\n",
    "\n",
    "    input_spec\n",
    "    <property object at 0x00000138BBCE7D60>\n",
    "\n",
    "    _trackable_saved_model_saver\n",
    "    <property object at 0x00000138BBCE7E00>\n",
    "\n",
    "    _keras_api_names\n",
    "    ('keras.Sequential', 'keras.models.Sequential')\n",
    "\n",
    "    _keras_api_names_v1\n",
    "    ('keras.Sequential', 'keras.models.Sequential')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**properties**\n",
    "\n",
    "    metrics\n",
    "\n",
    "    metrics_names\n",
    "\n",
    "    distribute_strategy\n",
    "\n",
    "    run_eagerly\n",
    "\n",
    "    _compile_was_called\n",
    "\n",
    "    _trackable_saved_model_saver\n",
    "\n",
    "**functions**\n",
    "\n",
    "    get_weights\n",
    "\n",
    "    load_weights\n",
    "\n",
    "    compile\n",
    "\n",
    "    \\_get_optimizer\n",
    "\n",
    "    \\_reset_compile_cache\n",
    "\n",
    "    train_step\n",
    "\n",
    "    make_train_function\n",
    "\n",
    "    fit\n",
    "    <function Model.fit at 0x000002760FEBAA60>\n",
    "\n",
    "    test_step\n",
    "    <function Model.test_step at 0x000002760FEBAAF0>\n",
    "\n",
    "    make_test_function\n",
    "    <function Model.make_test_function at 0x000002760FEBAB80>\n",
    "\n",
    "    evaluate\n",
    "    <function Model.evaluate at 0x000002760FEBACA0>\n",
    "\n",
    "    predict_step\n",
    "    <function Model.predict_step at 0x000002760FEBAD30>\n",
    "\n",
    "    make_predict_function\n",
    "    <function Model.make_predict_function at 0x000002760FEBADC0>\n",
    "\n",
    "    predict\n",
    "    <function Model.predict at 0x000002760FEBAEE0>\n",
    "\n",
    "    reset_metrics\n",
    "    <function Model.reset_metrics at 0x000002760FEBAF70>\n",
    "\n",
    "    train_on_batch\n",
    "    <function Model.train_on_batch at 0x000002760FEBC040>\n",
    "\n",
    "    test_on_batch\n",
    "    <function Model.test_on_batch at 0x000002760FEBC0D0>\n",
    "\n",
    "    predict_on_batch\n",
    "    <function Model.predict_on_batch at 0x000002760FEBC160>\n",
    "\n",
    "    fit_generator\n",
    "    <function Model.fit_generator at 0x000002760FEBC310>\n",
    "\n",
    "    evaluate_generator\n",
    "    <function Model.evaluate_generator at 0x000002760FEBC430>\n",
    "\n",
    "    predict_generator\n",
    "    <function Model.predict_generator at 0x000002760FEBC550>\n",
    "\n",
    "    _check_call_args\n",
    "    <function Model._check_call_args at 0x000002760FEBC1F0>\n",
    "\n",
    "    _validate_compile\n",
    "    <function Model._validate_compile at 0x000002760FEBC5E0>\n",
    "\n",
    "    _maybe_load_initial_epoch_from_ckpt\n",
    "    <function Model._maybe_load_initial_epoch_from_ckpt at 0x000002760FEBC670>\n",
    "\n",
    "    _assert_compile_was_called\n",
    "    <function Model._assert_compile_was_called at 0x000002760FEBC700>\n",
    "\n",
    "    _set_inputs\n",
    "    <function Model._set_inputs at 0x000002760FEBC790>\n",
    "\n",
    "    _list_functions_for_serialization\n",
    "    <function Model._list_functions_for_serialization at 0x000002760FEBC8B0>\n",
    "\n",
    "    _should_eval\n",
    "    <function Model._should_eval at 0x000002760FEBC940>\n",
    "\n",
    "    _get_compile_args\n",
    "    <function Model._get_compile_args at 0x000002760FEBC9D0>\n",
    "\n",
    "    _get_callback_model\n",
    "    <function Model._get_callback_model at 0x000002760FEBCA60>\n",
    "\n",
    "    _in_multi_worker_mode\n",
    "    <function Model._in_multi_worker_mode at 0x000002760FEBCAF0>\n",
    "\n",
    "    _get_distribution_strategy\n",
    "    <function Model._get_distribution_strategy at 0x000002760FEBCB80>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras.Model()\n",
    "`keras.Model(*args, **kwargs)`\n",
    "\n",
    "**Docstring**:\n",
    "\n",
    "`Model`将网络层进行包装，返回能够进行训练和推理操作的对象；创建模型之后，便可以使用`.compile()`方法配置损失和度量，使用`.fit()`方法训练模型，用`.predict()`方法进行预测；更多细节参见 [Keras 训练模型的相关指导](http://localhost:8888/notebooks/Help_Viewer_Python/TensorFlow/TF2/Guide/Keras/02.Train_a_Model.ipynb)\n",
    "\n",
    "**两种创建模型方法**：\n",
    "\n",
    "1. 使用 functional API；即从`Input`开始先后连接不同的网络层的实例调用，以指明模型向前传播的方式，最后利用输入和输出创建模型；更多关于 functional API 参见[相关指导](http://localhost:8888/notebooks/Help_Viewer_Python/TensorFlow/TF2/Guide/Keras/01.Create_a_Model.ipynb)；\n",
    "```python\n",
    "inputs = keras.Input(shape=(64,))\n",
    "x = layers.Dense(16, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "2. 继承`Model`类，并在`__init__()`方法中定义网络的层，在`call`方法中定义网络向前传播的方式；此外，在`call`方法中还可以设置`training`参数，用以指明模型在训练和推断时执行的不同的操作；更多关于通过类继承创建模型的方法，请参见[相关指导](http://localhost:8888/notebooks/Help_Viewer_Python/TensorFlow/TF2/Guide/Keras/01.Create_a_Model.ipynb)；\n",
    "\n",
    "```python\n",
    "class Model(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(4, activation=tf.nn.relu)\n",
    "        self.dense2 = layers.Dense(5, activation=tf.nn.softmax)\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x, training=training)\n",
    "        return self.dense2(x)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**File**:  \\keras\\engine\\training.py\n",
    "\n",
    "**Type**:           type\n",
    "\n",
    "**Subclasses**:     Sequential, Model, \\_LinearModel, LinearModel, WideDeepModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras.Model.compile()\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=None,\n",
    "    metrics=None,\n",
    "    loss_weights=None,\n",
    "    sample_weight_mode=None,\n",
    "    weighted_metrics=None,\n",
    "    **kwargs,\n",
    ")\n",
    "```\n",
    "为模型进行训练相关配置\n",
    "\n",
    "**Args**\n",
    "\n",
    "- optimizer: 接受表示优化器的字符串，或`keras.optimizers`模块中的优化器实例；\n",
    "\n",
    "- loss: 接受代表目标函数名称的字符串，或自定义的目标函数，或`.keras.losses.Loss`实例；若模型含有多个输出，可以传递一个字典或列表，以对每个输出使用不同的损失；最终模型的损失值会是所有单个损失的总和；\n",
    "    - 对于自定义目标函数，其应满足范式`loss = fn(y_true, y_pred)`，其中`y_true`除在函数是稀疏分类交叉熵损失时形状为`[batch_size, d0, .. dN-1]`，否则形状应为`[batch_size, d0, .. dN]`；`y_pred`形状也应为`[batch_size, d0, .. dN]`；\n",
    "    - 对于`Loss`实例，若其参数`reduction`被指明为 None，则返回的张量形状为`[batch_size, d0, .. dN-1]`，即对每个样本或每个时间步的损失值；否则返回标量张量；\n",
    "\n",
    "- metrics: 应为一个列表，其每个元素可以是代表表示度量的字符串，或自定义函数，或`keras.metrics.Metric`实例；对于多输出模型，可以通过传递一个字典为不同输出指定不同度量，例如`metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`，或通过传递一个列表进行指定，例如`metrics=[['accuracy'], ['accuracy', 'mse']]`或`metrics=['accuracy', ['accuracy', 'mse']]`；\n",
    "    - 对于自定义函数，其应满足范式`result = fn(y_true, y_pred)`\n",
    "    - 对于字符串形式，例如`'accuracy'`或`'acc'`，会基于模型使用的损失函数及输出形状，将其视为`keras.metrics`模块中的`BinaryAccuracy`、`CategoricalAccuracy`、`SparseCategoricalAccuracy`中的一种；对于`'crossentropy'`、`'ce'`类似；\n",
    "\n",
    "- loss_weights: 为模型不同输出的损失加权的列表或字典，其每个元素应为标量浮点型对象；模型最终的损失则为这些损失的加权和；对于列表，损失和权重顺序是一一对应的；对于字典，其键值应为输出的名称；\n",
    "\n",
    "- sample_weight_mode: 如果需要对每个时间步采样进行的加权 (二维加权)，可以将其设置为`\"temporal\"`；None 默认对每个样本进行加权 (一维加权)；如果模型有多个输出，可以传递字典或由模式组成的列表，以对每个输出指定不同的`sample_weight_mode`；\n",
    "\n",
    "- weighted_metrics: 由`fit()`方法所接收的`sample_weight`或`class_weight`参数所评估和加权的指标列表；\n",
    "\n",
    "- \\*\\*kwargs: 其他附加参数，若需要即时执行，可传递`run_eagerly=True`.\n",
    "\n",
    "**Type**:      function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.Model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras.Model.fit()\n",
    "```python\n",
    "model.fit(\n",
    "    x=None, y=None,\n",
    "    batch_size=None,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "```\n",
    "对模型进行训练和验证，并返回一个`History`的对象，其`History.history`属性记录了各 epoch 下的训练和验证的损失值和度量值；\n",
    "   \n",
    "**Args**:\n",
    "- x: 输入数据，其可以是:\n",
    "    - Numpy 数组或类数组；对于多输入可以是数组组成的列表\n",
    "    - TF 张量；对于多输入可以是张量组成的列表\n",
    "    - 若模型指定了输入的名称，可以是以名称为键值的字典\n",
    "    - `tf.data`的数据集，其应返回`(inputs, targets)`或`(inputs, targets, sample_weights)`\n",
    "    - 一个生成器，或`keras.utils.Sequence`，其应返回`(inputs, targets)`或`(inputs, targets, sample_weights)`<br>\n",
    " \n",
    " 一种常见的模式是将`tf.data.Dataset`、生成器或`tf.keras.utils.Sequence`传递给`x`，这种方式不仅可以生成输入数据，也会生成输出数据和样本权重；Keras 要求这些类迭代器对象的输出是明确的，迭代器返回的应是长度为 1、2 或 3 的元组，其中第二个和第三个可省略元素将分别对应`y`和`sample_weight`；所返回和任何类型数据均被视为输入数据；迭代器生成的字典的外部结构也应遵循上述关于元组的约定，例如`({\"x0\": x0， \"x1\": x1}， y)`；keras 无法从字典的单个键中提取输入输出和权重；需要注意的是，`x`不支持`namedtuple`数据类型，这是因为这种数据类型既是有序数据类型，也是一个映射型数据类型，进而给定一个`namedtuple(\"example_tuple\", [\"y\", \"x\"])`形式的 namedtuple，对其解析时很难确定是否要颠倒数据排列的顺序；对于`namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`形式的 namedtuple，很难断言应将其视为单个输入数据，还是应将其视为输入输出和权重的组合形式；\n",
    "\n",
    "\n",
    "- y: 目标数据，其类型应与`x`一致，当`x`为`Dataset`、生成器或`keras.utils.Sequence`实例时不需要指定`y`\n",
    "\n",
    "\n",
    "- batch_size: None 时为 32，若数据为`Dataset`、生成器或`keras.utils.Sequence`实例，则不需要指定`batch_size`，因为这些对象会自动生成 batch\n",
    "\n",
    "\n",
    "- epochs: 默认为 1，训练时遍历`range(initial_epoch, epochs)`\n",
    "\n",
    "\n",
    "- verbose: 可以是 {0, 1, 2}，默认 1；0 表示不显示任何信息；1 表示显示进度条；2 表示每个 epoch 显示分割线；需要注意的是，将进度条记录到日志文件中通常不会很有帮助，进而在不以交互方式运行时建议使用模式 2；\n",
    "\n",
    "\n",
    "- callbacks: `keras.callbacks.Callback`实例组成的列表；训练时使用的 callback，详见`tf.keras.callbacks`\n",
    "\n",
    "\n",
    "- validation_split: (0, 1) 间的浮点数，用于指明从训练集中分割出的验证集占比；分割操作是在乱序之前从提供的训练集最后若干样本中选择的；当`x`为`Dataset`、生成器或`keras.utils.Sequence`实例时不支持此参数\n",
    "\n",
    "\n",
    "- validation_data: 即验证集；该参数会覆盖`validation_split`；该参数可以是`(x_val, y_val)`形式的 Numpy 数组或张量，或`(x_val, y_val, val_sample_weights)`形式的 Numpy 数组，或数据集形式；对于前两种情况，必须指明`batch_size`；对于最后一种情况，必须指明`validation_steps`；需要注意的是`validation_data`不支持字典、生成器、`keras.utils.Sequence`实例类型；\n",
    "\n",
    "\n",
    "- shuffle: 可以是布尔值，用于指明是否在每个 epoch 之前对训练数据进行乱序；或为`'batch'`；`x`是生成器时则忽略此参数；`'batch'`是处理 HDF5 数据的一个特殊选项；当`steps_per_epoch`不为 None 时不起作用\n",
    "\n",
    "\n",
    "- class_weight: 应为字典形式，其键值为类别的索引，取值为训练期间计算损失函数时不同类别的权重值\n",
    "\n",
    "\n",
    "- sample_weight: 训练样本的加权值所组成的 Numpy 数组；对于非时序数据，默认将形状为`(samples,)`的数组中的权重值按索引对应至样本；对于时序数据，默认将形状为`(samples, sequence_length)`的数组中的权重值按索引对应至每个样本的每个时间步的输入；使用时序数据时，须确保`compile()`函数中指明了`sample_weight_mode=\"temporal\"`；当`x`为`Dataset`、生成器或`keras.utils.Sequence`实例时不支持此参数；\n",
    "\n",
    "\n",
    "- initial_epoch: 起始 epoch\n",
    "\n",
    "\n",
    "- steps_per_epoch: 可以是整型或 None；None 时默认取总样本数与 batch 大小的商，当无法以这种方式确定时取 1；若`x`为`tf.data`数据集且`steps_per_epoch`为 None，则默认所有数据在一个 epoch 内使用；当使用无限重复的数据集时，必须指定此参数；此参数不支持输入为数组的情况\n",
    "\n",
    "\n",
    "- validation_steps: 仅在为`validation_data`指定了`tf.data`的数据集时起作用；表示每每次验证执行的步数，即使用的 batch 数量；None 时会在一个 epoch 中使用所有的验证数据；若指明了`validation_steps`且一个 epoch 中仅使用到了验证集的部分数据，则每次进行验证时仍使用同样的一部分数据\n",
    "\n",
    "\n",
    "- validation_batch_size: 整型或 None；默认与`batch_size`相等；当数据为`Dataset`、生成器或`keras.utils.Sequence`实例时不支持此参数；\n",
    "\n",
    "\n",
    "- validation_freq: 可以是整型或`collections_abc.Container`实例，如列表、元祖等；只在提供了验证集时起作用；若为整型，则代表进行验证的频率；若为`Container`实例，则代表进行验证的 epoch 的序号，例如`validation_freq=[1, 2, 10]`代表在第 1、2、10 个 epoch 进行验证\n",
    "\n",
    "\n",
    "- max_queue_size: 整型，仅适用于输入为生成器或`keras.utils.Sequence`的情况，用于指定输入的最大生成队列长度；默认为 10；\n",
    "\n",
    "\n",
    "- workers: 整型，仅适用于输入为生成器或`keras.utils.Sequence`的情况；使用基于进程 (process-based) 的线程 (threading) 时要启动的最大进程数；默认为 1；被指定为 0 时会在主线程上执行生成器；\n",
    "\n",
    "\n",
    "- use_multiprocessing: 布尔型，仅适用于输入为生成器或`keras.utils.Sequence`的情况；默认为 False；True 时使用基于进程的线程；由于其实现依赖于多处理，所以请勿将无法 pickle 的参数传递给生成器，因为无法 pickle 的参数很难传递给子进程\n",
    "\n",
    "**Type**:      function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras.Model.evaluate()\n",
    "```python\n",
    "keras.Model.evaluate(\n",
    "    x=None,\n",
    "    y=None,\n",
    "    batch_size=None,\n",
    "    verbose=1,\n",
    "    sample_weight=None,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    return_dict=False,\n",
    ")\n",
    "```\n",
    "在测试集上计算模型的损失和度量值\n",
    "\n",
    "**Args**\n",
    "- x: 输入数据，其可以是:\n",
    "    - Numpy 数组或类数组；对于多输入可以是数组组成的列表\n",
    "    - TF 张量；对于多输入可以是张量组成的列表\n",
    "    - 若模型指定了输入的名称，可以是以名称为键值的字典\n",
    "    - `tf.data.Dataset`实例；\n",
    "    - 一个生成器，或`keras.utils.Sequence`；\n",
    "\n",
    "- y: 目标数据，其类型应与`x`一致，当`x`为`Dataset`、生成器或`keras.utils.Sequence`实例时不需要指定`y`\n",
    "\n",
    "- batch_size: None 时为 32，若数据为`Dataset`、生成器或`keras.utils.Sequence`实例，则不需要指定`batch_size`，因为这些对象会自动生成 batch\n",
    "\n",
    "- verbose: 可以是 {0, 1, 2}，默认 1；0 表示不显示任何信息；1 表示显示进度条；\n",
    "\n",
    "- sample_weight: 测试样本的加权值所组成的 Numpy 数组；对于非时序数据，默认将形状为`(samples,)`的数组中的权重值按索引对应至样本；对于时序数据，默认将形状为`(samples, sequence_length)`的数组中的权重值按索引对应至每个样本的每个时间步的输入；使用时序数据时，须确保`compile()`函数中指明了`sample_weight_mode=\"temporal\"`；当`x`为`Dataset`、生成器或`keras.utils.Sequence`实例时不支持此参数；\n",
    "\n",
    "- steps: 整型或 None，测试的总步数；默认 None 时忽略此参数，此时若`x`为`Dataset`，则在整个测试集上进行测试；此参数不支持数组的输入\n",
    "\n",
    "- callbacks: `keras.callbacks.Callback`实例组成的列表；评估时使用的 callback，详见`tf.keras.callbacks`\n",
    "\n",
    "- max_queue_size: 整型，仅适用于输入为生成器或`keras.utils.Sequence`的情况，用于指定输入的最大生成队列长度；默认为 10；\n",
    "\n",
    "- workers: 整型，仅适用于输入为生成器或`keras.utils.Sequence`的情况；使用基于进程 (process-based) 的线程 (threading) 时要启动的最大进程数；默认为 1；被指定为 0 时会在主线程上执行生成器；\n",
    "\n",
    "- use_multiprocessing: 布尔型，仅适用于输入为生成器或`keras.utils.Sequence`的情况；默认为 False；True 时使用基于进程的线程；由于其实现依赖于多处理，所以请勿将无法 pickle 的参数传递给生成器，因为无法 pickle 的参数很难传递给子进程\n",
    "\n",
    "- return_dict: True 时将损失和度量以字典的形式返回，键为相应的名称；False 时则返回列表；默认 False\n",
    "\n",
    "\n",
    "Returns: Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute `model.metrics_names` will give you the display labels for the scalar outputs.\n",
    "\n",
    "**Type**:      function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
