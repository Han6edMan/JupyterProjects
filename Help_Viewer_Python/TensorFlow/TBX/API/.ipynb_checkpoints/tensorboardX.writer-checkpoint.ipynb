{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorboardX.writer as writer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writer.SummaryWriter()\n",
    "```python\n",
    "SummaryWriter(\n",
    "    logdir=None,\n",
    "    comment='',\n",
    "    purge_step=None,\n",
    "    max_queue=10,\n",
    "    flush_secs=120,\n",
    "    filename_suffix='',\n",
    "    write_to_disk=True,\n",
    "    log_dir=None,\n",
    "    **kwargs,\n",
    ")\n",
    "```\n",
    "\n",
    "Docstring:     \n",
    "Writes entries directly to event files in the logdir to be\n",
    "consumed by TensorBoard.\n",
    "\n",
    "The `SummaryWriter` class provides a high-level API to create an event file\n",
    "in a given directory and add summaries and events to it. The class updates the\n",
    "file contents asynchronously. This allows a training program to call methods\n",
    "to add data to the file directly from the training loop, without slowing down\n",
    "training.\n",
    "Init docstring:\n",
    "Creates a `SummaryWriter` that will write out events and summaries\n",
    "to the event file.\n",
    "\n",
    "Args:\n",
    "    logdir (string): Save directory location. Default is\n",
    "      runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run.\n",
    "      Use hierarchical folder structure to compare\n",
    "      between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc.\n",
    "      for each new experiment to compare across them.\n",
    "    comment (string): Comment logdir suffix appended to the default\n",
    "      ``logdir``. If ``logdir`` is assigned, this argument has no effect.\n",
    "    purge_step (int):\n",
    "      When logging crashes at step :math:`T+X` and restarts at step :math:`T`,\n",
    "      any events whose global_step larger or equal to :math:`T` will be\n",
    "      purged and hidden from TensorBoard.\n",
    "      Note that crashed and resumed experiments should have the same ``logdir``.\n",
    "    max_queue (int): Size of the queue for pending events and\n",
    "      summaries before one of the 'add' calls forces a flush to disk.\n",
    "      Default is ten items.\n",
    "    flush_secs (int): How often, in seconds, to flush the\n",
    "      pending events and summaries to disk. Default is every two minutes.\n",
    "    filename_suffix (string): Suffix added to all event filenames in\n",
    "      the logdir directory. More details on filename construction in\n",
    "      tensorboard.summary.writer.event_file_writer.EventFileWriter.\n",
    "    write_to_disk (boolean):\n",
    "      If pass `False`, SummaryWriter will not write to disk.\n",
    "\n",
    "Examples::\n",
    "\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "    # create a summary writer with automatically generated folder name.\n",
    "    writer = SummaryWriter()\n",
    "    # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n",
    "\n",
    "    # create a summary writer using the specified folder name.\n",
    "    writer = SummaryWriter(\"my_experiment\")\n",
    "    # folder location: my_experiment\n",
    "\n",
    "    # create a summary writer with comment appended.\n",
    "    writer = SummaryWriter(comment=\"LR_0.1_BATCH_16\")\n",
    "    # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/\n",
    "File:           d:\\programfiles\\miniconda3\\lib\\site-packages\\tensorboardx\\writer.py\n",
    "Type:           type\n",
    "Subclasses:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-f11e45456235>:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight)\n",
      "<ipython-input-30-f11e45456235>:78: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  out = F.avg_pool2d(out, int(out.shape[3]))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv11 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv11(self.conv1(x))))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, int(out.shape[3]))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.bn2(out)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "summary = writer.SummaryWriter(\"../test/SummaryWriter_test\")\n",
    "dummy_input = torch.rand(1, 3, 32, 32)\n",
    "model = resnet20()\n",
    "summary.add_graph(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1])\n",
    "x  # ==> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__deepcopy__\n",
      "__reduce_ex__\n",
      "__setstate__\n",
      "__repr__\n",
      "backward\n",
      "register_hook\n",
      "reinforce\n",
      "detach\n",
      "detach_\n",
      "retain_grad\n",
      "is_shared\n",
      "share_memory_\n",
      "__reversed__\n",
      "norm\n",
      "lu\n",
      "stft\n",
      "istft\n",
      "resize\n",
      "resize_as\n",
      "split\n",
      "unique\n",
      "unique_consecutive\n",
      "__rsub__\n",
      "__rdiv__\n",
      "__rtruediv__\n",
      "__itruediv__\n",
      "__pow__\n",
      "__format__\n",
      "__ipow__\n",
      "__rpow__\n",
      "__floordiv__\n",
      "__rfloordiv__\n",
      "__neg__\n",
      "__eq__\n",
      "__ne__\n",
      "__lt__\n",
      "__le__\n",
      "__gt__\n",
      "__ge__\n",
      "__abs__\n",
      "__len__\n",
      "__iter__\n",
      "__hash__\n",
      "__dir__\n",
      "__array__\n",
      "__array_wrap__\n",
      "__contains__\n",
      "refine_names\n",
      "align_to\n",
      "unflatten\n",
      "rename_\n",
      "rename\n",
      "_update_names\n"
     ]
    }
   ],
   "source": [
    "for k, v in torch.Tensor.__dict__.items():\n",
    "    if callable(v):\n",
    "        print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
