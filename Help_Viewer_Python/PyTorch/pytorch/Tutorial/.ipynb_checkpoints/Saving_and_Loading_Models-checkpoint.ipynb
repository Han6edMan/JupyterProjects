{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "collectible-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "advisory-ranking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/2], step[200/625]:\tLoss=0.0286\n",
      "Epoch[1/2], step[400/625]:\tLoss=0.0220\n",
      "Epoch[1/2], step[600/625]:\tLoss=0.0186\n",
      "Epoch[2/2], step[200/625]:\tLoss=0.0158\n",
      "Epoch[2/2], step[400/625]:\tLoss=0.0144\n",
      "Epoch[2/2], step[600/625]:\tLoss=0.0133\n",
      "==> Model's state_dict:\n",
      "linear0.weight\ttorch.Size([300, 784])\n",
      "linear0.bias\ttorch.Size([300])\n",
      "linear1.weight\ttorch.Size([100, 300])\n",
      "linear1.bias\ttorch.Size([100])\n",
      "linear2.weight\ttorch.Size([10, 100])\n",
      "linear2.bias\ttorch.Size([10])\n",
      "\n",
      "\n",
      "==> Optimizer's state_dict:\n",
      "state\n",
      "{0: {'momentum_buffer': tensor([[-0.0038, -0.0038, -0.0038,  ..., -0.0038, -0.0038, -0.0038],\n",
      "        [ 0.0028,  0.0028,  0.0028,  ...,  0.0028,  0.0028,  0.0028],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        ...,\n",
      "        [-0.0041, -0.0041, -0.0041,  ..., -0.0041, -0.0041, -0.0041],\n",
      "        [ 0.0001,  0.0001,  0.0001,  ...,  0.0001,  0.0001,  0.0001],\n",
      "        [-0.0074, -0.0074, -0.0074,  ..., -0.0074, -0.0074, -0.0074]])}, 1: {'momentum_buffer': tensor([ 9.0397e-03, -6.6328e-03,  2.8512e-03, -1.3583e-03,  1.0376e-02,\n",
      "        -3.3182e-03,  1.5661e-02, -4.2863e-04,  2.2313e-02, -4.2674e-03,\n",
      "        -9.2761e-03, -5.1311e-04,  1.1621e-02,  2.8001e-03, -6.3474e-03,\n",
      "         7.1871e-03,  2.9149e-03,  1.3332e-02, -9.8368e-03,  3.9122e-03,\n",
      "        -9.7753e-03, -9.0180e-03, -3.1259e-04,  8.3269e-03, -2.1831e-03,\n",
      "         8.4285e-03,  1.1758e-02, -2.6762e-03,  4.2403e-03,  4.0387e-03,\n",
      "        -7.2888e-03,  1.2374e-04,  1.7890e-02,  2.1209e-03,  1.4061e-03,\n",
      "        -4.7553e-04, -1.3230e-03,  5.9436e-03,  1.6085e-02, -1.4893e-03,\n",
      "        -9.8093e-04,  5.8771e-03, -7.1708e-03, -1.5911e-02, -3.9698e-03,\n",
      "        -5.4757e-03,  2.8678e-03, -1.3655e-02, -8.0718e-03,  2.1583e-03,\n",
      "         2.7427e-03, -2.7782e-03, -5.4560e-03,  1.4433e-03, -8.0427e-03,\n",
      "         4.2544e-03, -8.6965e-03, -2.0081e-03, -3.0991e-03,  8.5238e-03,\n",
      "         5.8139e-02, -4.8955e-03,  3.3531e-03, -7.0238e-03,  6.8315e-03,\n",
      "         2.6681e-03, -7.1314e-03, -1.4182e-03,  1.0056e-03, -5.8027e-04,\n",
      "        -7.0036e-03, -4.5236e-03,  3.2164e-03,  1.1841e-02,  2.4094e-03,\n",
      "        -1.7025e-03,  1.4656e-02, -1.5702e-02, -3.1242e-03, -6.4389e-03,\n",
      "        -1.7227e-03,  4.9919e-03, -2.2329e-03, -3.2438e-03, -7.0486e-03,\n",
      "        -4.4171e-03, -7.4710e-03,  3.4102e-03,  1.9069e-03, -2.6550e-03,\n",
      "        -2.8043e-03,  1.9007e-04,  1.1334e-03, -7.4465e-03, -1.8706e-03,\n",
      "        -1.2911e-03,  6.8016e-03, -2.7225e-03,  2.0243e-03, -3.1581e-04,\n",
      "        -1.3000e-03, -4.0893e-05,  5.3007e-03,  3.8176e-03, -7.3904e-03,\n",
      "        -1.5656e-02, -2.2043e-03, -2.7137e-03,  2.8441e-03, -1.2894e-03,\n",
      "        -5.5427e-04, -3.0274e-03, -1.3428e-03,  6.5323e-03,  9.7397e-03,\n",
      "        -4.1217e-03,  5.6241e-03,  7.6624e-03,  3.7668e-04,  9.1485e-04,\n",
      "         2.0640e-02, -5.9282e-03, -9.8768e-04, -7.2938e-03,  6.9499e-03,\n",
      "        -8.1262e-03,  1.0689e-02,  1.3645e-04, -5.7536e-03, -6.6498e-03,\n",
      "        -1.9059e-03, -5.8094e-03, -1.6192e-04,  1.0850e-02,  4.4764e-05,\n",
      "        -2.4570e-03,  2.3315e-02,  1.6795e-02, -9.6816e-03,  1.6275e-02,\n",
      "        -3.4162e-03, -2.0578e-02, -1.7982e-02, -4.1902e-03,  1.3027e-02,\n",
      "        -1.8793e-04, -1.1101e-02, -4.4695e-03,  2.6866e-03, -2.2477e-03,\n",
      "         5.8563e-03, -9.4771e-04,  3.4772e-04, -1.9848e-03, -1.1960e-02,\n",
      "         1.9669e-03,  6.6056e-03,  6.3903e-03, -2.1972e-03,  9.3895e-03,\n",
      "        -3.6184e-03, -1.0115e-02,  1.5729e-03, -3.9077e-04, -2.1243e-03,\n",
      "        -7.6362e-03,  1.9108e-03, -2.7368e-03, -5.6937e-03,  5.8138e-03,\n",
      "         7.1814e-03, -1.5619e-03,  5.7799e-05, -2.7959e-03, -1.1581e-02,\n",
      "        -9.5959e-06,  9.0729e-04,  1.8860e-02,  3.1585e-04, -5.4978e-03,\n",
      "         2.2369e-03, -2.3666e-03,  7.9373e-05, -2.0075e-02,  4.5756e-03,\n",
      "         6.6694e-05,  1.3866e-03, -2.8550e-03,  6.7950e-03,  7.8548e-04,\n",
      "         6.2443e-03,  2.7648e-02, -3.3269e-03,  1.4261e-03,  1.4349e-03,\n",
      "        -3.3709e-03,  1.3922e-02, -1.4593e-04,  1.0082e-02, -1.8438e-03,\n",
      "         4.1721e-03, -1.2417e-02,  3.4429e-03, -7.7807e-03, -2.5503e-03,\n",
      "        -4.4433e-03,  8.4188e-03, -3.5152e-04, -4.3874e-03,  1.7108e-02,\n",
      "        -7.8700e-03, -7.7525e-03,  1.3496e-03, -3.8085e-04, -6.5062e-03,\n",
      "         2.5269e-03,  1.9087e-04,  3.9848e-03, -6.6663e-04, -1.8463e-03,\n",
      "         2.9877e-03, -9.4277e-03, -3.2140e-04,  2.9125e-04, -1.0781e-02,\n",
      "         1.5857e-02, -7.2846e-04,  2.3691e-02,  3.9317e-03, -2.3823e-03,\n",
      "         3.3992e-03,  2.4565e-03,  3.1913e-03, -8.8670e-03,  5.5771e-03,\n",
      "         8.2875e-03,  6.1196e-03, -2.8638e-03, -5.3616e-03, -1.8879e-02,\n",
      "        -4.7405e-03, -5.8570e-03,  6.2407e-03, -6.0700e-03,  9.2730e-03,\n",
      "         1.2750e-03,  5.4414e-03, -1.3211e-02,  8.6948e-04,  2.7027e-02,\n",
      "         1.0071e-02, -3.1753e-04,  8.7628e-03, -5.9552e-04,  7.4843e-03,\n",
      "         4.9544e-03, -5.4894e-03,  2.6724e-03, -5.0642e-03, -6.2468e-06,\n",
      "         3.4781e-03,  1.2650e-03, -3.8251e-03,  2.1681e-03,  6.0995e-03,\n",
      "        -2.4850e-03,  3.5504e-03, -3.6196e-03, -1.6891e-02,  1.2062e-02,\n",
      "        -4.5876e-03,  1.6505e-03, -6.1197e-03,  2.9832e-03,  9.7121e-03,\n",
      "         3.7882e-03,  1.6702e-03, -1.7655e-03, -4.9091e-03, -2.8964e-02,\n",
      "        -5.3290e-03,  6.5660e-03, -6.7088e-03, -6.4850e-03,  8.2812e-03,\n",
      "        -1.2130e-03,  1.9604e-03,  7.9986e-03,  1.3450e-02,  3.6324e-03,\n",
      "        -8.6929e-03,  1.8918e-03, -1.7339e-03,  3.9257e-03,  9.1319e-03,\n",
      "        -5.3651e-03, -8.0605e-03,  9.6648e-03, -3.2713e-04,  1.7420e-02])}, 2: {'momentum_buffer': tensor([[-1.2554e-04,  2.6668e-04, -7.0393e-04,  ..., -2.2443e-03,\n",
      "         -9.9412e-04, -2.3757e-03],\n",
      "        [ 2.2591e-02,  5.3808e-03,  1.1415e-02,  ...,  9.1581e-03,\n",
      "          9.6252e-03,  3.5891e-02],\n",
      "        [-1.1785e-01, -2.4427e-02, -6.8732e-03,  ..., -7.3036e-03,\n",
      "          1.2188e-02, -1.3693e-01],\n",
      "        ...,\n",
      "        [-8.9640e-03, -3.1928e-03, -2.7549e-03,  ..., -6.1680e-03,\n",
      "          5.9823e-03, -5.6514e-03],\n",
      "        [ 6.3119e-04,  1.3305e-03, -1.4338e-03,  ...,  1.6029e-03,\n",
      "         -4.2614e-03,  6.7359e-03],\n",
      "        [ 4.2762e-02, -2.1557e-03, -1.0521e-02,  ...,  1.0011e-02,\n",
      "         -1.3081e-02,  2.3844e-02]])}, 3: {'momentum_buffer': tensor([-3.2809e-03,  8.8197e-03, -6.1481e-02,  1.3720e-03, -1.0629e-02,\n",
      "        -2.8093e-03, -1.7702e-02, -1.9730e-02,  2.1066e-03,  5.4453e-04,\n",
      "        -1.8827e-02,  1.4889e-02, -3.5668e-03, -2.7166e-03,  1.2736e-03,\n",
      "         1.1153e-03, -4.4029e-02,  3.4338e-03,  2.5306e-03,  1.5750e-02,\n",
      "        -1.1537e-02, -2.8358e-02, -3.1814e-02,  4.2326e-02,  1.3660e-02,\n",
      "         6.2863e-03,  3.2407e-02,  5.4826e-03, -3.6385e-03, -8.1852e-03,\n",
      "        -9.5921e-03, -8.2255e-03,  1.5677e-03, -1.3466e-02,  4.7761e-02,\n",
      "         6.1778e-02, -7.8094e-04,  2.0806e-02,  3.4054e-04,  1.7868e-02,\n",
      "         3.2518e-03, -4.4614e-04,  2.1742e-02,  1.1045e-03,  2.4209e-02,\n",
      "         1.2014e-02,  7.7450e-03, -3.0739e-02,  2.2502e-02, -3.7553e-02,\n",
      "        -7.1450e-03, -1.9794e-02, -6.1621e-03, -2.2066e-02, -3.6389e-04,\n",
      "        -4.4302e-02,  7.2560e-03, -4.0877e-02,  4.3478e-03, -9.5143e-03,\n",
      "        -7.7211e-06, -1.4894e-02, -6.5993e-03, -2.0183e-04, -8.2609e-03,\n",
      "        -1.8993e-02,  8.5055e-03,  1.3926e-02, -2.1851e-02,  1.8560e-02,\n",
      "        -9.1912e-04,  2.8990e-02, -9.2698e-03, -2.1617e-02,  3.3383e-02,\n",
      "         1.8587e-03,  2.0852e-02,  2.2733e-02, -3.9341e-04, -1.4445e-02,\n",
      "         2.7767e-02, -2.5546e-02, -1.8587e-02, -1.1204e-02,  6.2601e-03,\n",
      "         6.2264e-05, -1.1949e-02, -6.2554e-03, -3.1434e-03,  6.1464e-04,\n",
      "         6.2193e-02, -1.1366e-02, -5.5505e-03,  4.0068e-04,  6.8743e-03,\n",
      "         3.5985e-03, -2.9261e-02, -3.1834e-03,  1.5627e-03, -2.4930e-03])}, 4: {'momentum_buffer': tensor([[ 1.0398e-02,  5.0415e-03,  5.9536e-02,  7.2361e-02,  4.1482e-03,\n",
      "          1.2725e-02, -1.0270e-03,  7.7555e-03,  2.4728e-03,  2.1329e-02,\n",
      "         -1.4731e-03,  2.6928e-02,  4.0826e-02,  1.1872e-02,  4.8342e-02,\n",
      "          2.6018e-02,  3.1483e-02,  2.4996e-02,  2.5166e-02,  1.5434e-02,\n",
      "          2.0500e-02,  7.4765e-03,  8.1296e-02,  4.2037e-03,  2.9534e-03,\n",
      "         -2.0571e-03,  3.6890e-02,  8.0365e-03,  4.8692e-04,  1.8412e-02,\n",
      "          3.7547e-02,  5.9943e-03,  5.1608e-04,  1.1021e-01,  1.3812e-02,\n",
      "          4.6591e-02,  3.7709e-03,  5.7498e-02,  1.9512e-02,  2.2607e-03,\n",
      "          2.6061e-02,  1.8929e-04,  1.2452e-01,  4.5133e-04,  5.7687e-02,\n",
      "          9.6729e-02,  1.5044e-02,  1.3836e-02,  5.4303e-02,  7.1403e-03,\n",
      "          5.8188e-02,  1.7350e-02,  1.7936e-02,  5.6064e-03,  5.4444e-03,\n",
      "          8.6910e-02,  2.8034e-02,  6.9013e-04,  9.4107e-03,  7.3705e-02,\n",
      "          1.1030e-05,  5.6568e-02,  2.3363e-02,  1.4175e-02,  7.2859e-03,\n",
      "          6.6320e-03,  1.9153e-02,  4.5263e-02,  3.5338e-02,  5.5802e-02,\n",
      "         -3.9345e-04,  1.8348e-03,  1.4872e-02,  1.9966e-02,  2.6849e-03,\n",
      "          3.8624e-02,  4.1580e-02,  7.8552e-02, -3.9712e-04,  4.4852e-02,\n",
      "          5.6507e-02,  6.6534e-02,  9.7137e-02,  9.7578e-02,  1.4156e-02,\n",
      "          2.0420e-04,  2.6828e-02,  2.7039e-03,  5.0849e-03,  3.3970e-03,\n",
      "          1.2822e-01,  4.4870e-03, -1.3948e-03,  9.9985e-06,  2.1084e-02,\n",
      "          3.3380e-02,  2.1507e-02,  2.9460e-02,  1.0104e-03,  7.4745e-03],\n",
      "        [-1.0696e-03, -1.4142e-03, -1.6112e-04, -2.9748e-02,  7.0153e-05,\n",
      "          3.7689e-04, -5.6163e-02, -9.4647e-03, -2.6741e-02, -9.9507e-03,\n",
      "         -1.7455e-02,  1.3283e-03, -1.5991e-02,  2.7432e-04, -4.1344e-03,\n",
      "          1.4221e-03,  6.1992e-04, -1.6943e-02,  1.3428e-04, -4.0872e-03,\n",
      "         -6.4778e-03, -1.1008e-02,  4.0470e-03, -1.0861e-02, -2.6707e-02,\n",
      "          7.4101e-06, -8.4727e-02, -7.3109e-04, -1.1046e-02, -6.7822e-03,\n",
      "         -5.3887e-02, -4.9908e-02, -9.8759e-03, -1.2781e-02, -3.2378e-02,\n",
      "         -3.7379e-02, -4.9667e-03, -1.0553e-02, -5.4235e-03, -3.0944e-02,\n",
      "          4.5562e-05,  1.8518e-04, -4.2949e-02, -1.8875e-02, -1.5099e-02,\n",
      "          4.3859e-04, -1.2536e-02, -5.7464e-02, -1.6518e-03, -1.8558e-02,\n",
      "          4.6112e-05, -6.6905e-03, -3.7878e-03, -3.2665e-02, -6.1682e-03,\n",
      "         -3.7375e-03, -4.5145e-04, -7.3737e-03, -7.0256e-03,  7.6635e-04,\n",
      "          5.6725e-07, -8.8657e-03, -8.0407e-03, -6.7069e-03, -3.5180e-02,\n",
      "         -2.4985e-03, -1.4525e-02,  1.6371e-04, -7.4621e-02, -5.0738e-03,\n",
      "         -7.4376e-06, -1.7357e-02, -1.1642e-02, -2.3281e-02, -3.8084e-02,\n",
      "         -6.0561e-02, -1.9023e-02, -4.2945e-02,  4.8101e-05, -2.4990e-03,\n",
      "         -2.0673e-02, -3.1238e-03,  1.1520e-03, -1.3621e-03,  1.3709e-04,\n",
      "         -1.9752e-02, -5.2068e-03, -1.1065e-02, -7.6537e-03,  1.7476e-05,\n",
      "         -4.8326e-02, -8.4436e-03, -1.6116e-03,  7.6986e-06,  3.7927e-04,\n",
      "         -1.7097e-03, -6.4323e-03, -3.1931e-03, -4.0109e-04, -2.8179e-02],\n",
      "        [-2.0964e-04,  5.7081e-02,  6.3076e-02, -4.4258e-02,  1.5163e-03,\n",
      "          2.4059e-02,  4.6131e-02,  2.2183e-02, -7.6620e-03,  4.2009e-03,\n",
      "          4.0973e-03,  4.7663e-02,  3.8316e-02,  8.3844e-02,  3.9143e-02,\n",
      "          4.8251e-02,  3.4568e-02,  1.1209e-03, -1.0921e-04,  7.1469e-02,\n",
      "         -7.3089e-03, -1.4048e-02,  3.1056e-03,  4.5078e-03,  4.5761e-03,\n",
      "         -5.7911e-04,  3.3450e-02,  6.0447e-04,  7.3697e-03, -1.2062e-02,\n",
      "         -8.9914e-03,  2.4307e-02,  8.2267e-04, -4.3187e-02,  3.0103e-03,\n",
      "         -1.3516e-02,  3.6346e-03,  1.9502e-04, -1.0957e-02,  9.7873e-02,\n",
      "         -7.0694e-03,  3.8592e-03, -8.7669e-02,  2.8500e-02,  8.2354e-04,\n",
      "         -1.7853e-02,  1.5987e-03,  2.9622e-02, -1.0004e-02,  3.5402e-02,\n",
      "          5.4309e-02, -5.8482e-03,  2.9646e-02, -1.5013e-02,  4.0752e-02,\n",
      "          3.8522e-03,  3.8353e-02, -3.3822e-03,  2.8856e-02,  2.9742e-02,\n",
      "          7.1476e-06, -1.6154e-03,  3.5510e-02,  8.7669e-03,  1.4006e-02,\n",
      "          3.8251e-03, -8.7583e-03,  9.9599e-05, -6.8703e-03,  5.0575e-03,\n",
      "         -9.5386e-04,  2.4345e-02,  3.8672e-03, -1.5549e-02,  6.5879e-03,\n",
      "         -2.2244e-02,  4.0602e-04, -2.2698e-02,  1.2875e-04,  2.4606e-02,\n",
      "          3.8081e-02,  1.0954e-02,  4.5607e-02,  1.8560e-02,  1.2018e-01,\n",
      "         -2.6006e-05,  2.6539e-02, -1.0412e-02, -7.5096e-03,  2.8814e-04,\n",
      "          6.0691e-03,  1.2919e-02, -3.4300e-03,  1.6355e-04, -5.4294e-03,\n",
      "          9.0218e-02,  2.4957e-02, -7.3908e-03,  5.5824e-02,  2.4897e-02],\n",
      "        [ 1.5186e-02,  1.8904e-01,  2.7327e-01,  1.0533e-01,  1.8455e-02,\n",
      "          1.3222e-02,  8.9495e-02,  1.0300e-01,  7.0881e-02,  1.4418e-01,\n",
      "          2.3894e-02,  3.0174e-01,  3.1343e-01,  1.0145e-02,  2.8906e-01,\n",
      "          1.1459e-01,  1.8856e-01,  1.6401e-02, -1.3826e-02,  1.2332e-01,\n",
      "          2.6881e-02,  1.5206e-01,  2.0991e-01,  1.6883e-01,  7.0976e-02,\n",
      "          1.5217e-03,  4.4204e-01,  7.9121e-04,  1.1127e-01,  1.0283e-01,\n",
      "          2.2087e-01,  7.5993e-02,  2.9061e-02,  1.0442e-01,  2.5945e-01,\n",
      "          1.7157e-01,  3.1245e-02,  1.8796e-01, -2.3870e-04,  5.0747e-02,\n",
      "         -8.2990e-03, -8.4798e-05,  7.1605e-02,  7.1110e-03,  4.0739e-01,\n",
      "         -5.2173e-03,  1.0786e-01,  2.9360e-02,  7.5652e-02,  7.0537e-02,\n",
      "          4.3016e-01,  2.1778e-01,  1.7806e-02,  5.8513e-02,  1.6265e-02,\n",
      "          2.0101e-01,  1.3280e-01,  5.5298e-02,  7.5649e-04,  1.6710e-01,\n",
      "         -1.6029e-05,  1.3179e-01,  2.8290e-02,  1.7809e-01,  2.2165e-02,\n",
      "          1.3030e-02,  1.3217e-01, -6.3730e-03,  3.5422e-01,  6.7742e-03,\n",
      "          1.4589e-03,  8.5621e-03, -3.0633e-03,  6.1157e-02,  1.9590e-01,\n",
      "          1.8946e-01,  9.2538e-02,  3.7100e-01,  9.9702e-04,  2.5796e-01,\n",
      "          1.7718e-02,  1.9990e-01,  1.4234e-01,  2.7384e-01,  8.9807e-03,\n",
      "          5.0295e-03,  3.3385e-02,  1.7357e-02,  1.4671e-02,  1.9837e-03,\n",
      "          2.8658e-01,  2.8839e-02, -2.8331e-03,  1.5833e-05, -4.2978e-03,\n",
      "          4.5654e-02,  1.0110e-01,  1.0278e-01,  1.3366e-02,  1.3742e-01],\n",
      "        [-4.4132e-03, -1.1939e-02,  4.9147e-02,  4.8417e-03,  1.2910e-03,\n",
      "         -1.2909e-02, -1.4022e-02, -2.6749e-02,  3.8918e-03,  1.3894e-02,\n",
      "          2.6909e-02, -5.6665e-03, -7.7384e-03, -1.0753e-02,  2.3416e-02,\n",
      "         -5.3213e-03,  1.4979e-02,  7.2453e-03,  4.9103e-04, -1.1508e-02,\n",
      "          2.1319e-03,  8.0822e-03,  1.6880e-02,  2.4648e-02,  1.3341e-02,\n",
      "          5.7850e-04, -2.4797e-02,  1.3093e-02, -6.7562e-03,  1.1919e-02,\n",
      "          7.7600e-03,  1.6784e-02,  8.0016e-03,  1.0805e-02,  1.9074e-03,\n",
      "          1.5299e-03,  1.7598e-02,  1.7334e-02,  1.2430e-03, -3.2234e-02,\n",
      "          3.2137e-03,  7.9003e-04,  3.6421e-03,  8.7439e-04,  9.3310e-03,\n",
      "          2.8881e-02,  5.2992e-03, -1.5356e-02,  3.2654e-02,  1.0925e-02,\n",
      "          6.0458e-03,  1.8351e-03,  9.4778e-03,  9.8915e-04, -9.1395e-03,\n",
      "          1.9076e-02,  4.1744e-02,  1.6830e-03, -2.1406e-04,  2.1995e-02,\n",
      "         -1.1945e-07,  8.8804e-03, -8.9782e-03,  1.1625e-02,  2.8585e-03,\n",
      "          1.0585e-02,  3.7455e-04,  3.1803e-02, -1.8132e-02,  1.5498e-02,\n",
      "          2.1384e-04,  3.9630e-02,  1.3781e-02,  3.6968e-03,  1.9704e-04,\n",
      "          8.5874e-03,  1.2947e-02,  3.5287e-03,  2.4867e-04, -9.6960e-03,\n",
      "          8.5773e-03,  1.5479e-02,  2.4810e-02,  2.2420e-02, -7.8188e-03,\n",
      "          1.6034e-02,  2.3364e-02,  1.4613e-02,  5.2271e-04, -4.5843e-04,\n",
      "          3.6594e-02,  1.3546e-02,  3.1048e-03, -1.1263e-04,  4.4975e-04,\n",
      "          1.6009e-02,  1.4080e-02,  4.8205e-02, -8.3948e-03,  2.4432e-02],\n",
      "        [ 1.4062e-03, -1.9656e-01, -2.5175e-01, -4.0246e-02, -1.9918e-02,\n",
      "         -8.2830e-04, -3.6057e-02, -4.9620e-02, -7.0497e-03, -5.0537e-02,\n",
      "          5.1382e-04, -2.0504e-01, -2.7894e-01,  4.2675e-03, -1.6571e-01,\n",
      "         -1.4564e-01, -1.1087e-01, -1.2032e-02, -9.0356e-03, -1.1597e-01,\n",
      "         -2.0754e-02, -1.3833e-01, -2.0753e-01, -8.2611e-02, -1.6029e-02,\n",
      "         -1.8944e-03, -2.5016e-01,  5.5930e-03, -7.8545e-02, -7.5444e-02,\n",
      "         -1.0989e-01,  2.9009e-02,  1.5404e-02, -1.1980e-01, -1.5952e-01,\n",
      "         -1.1695e-01, -2.3202e-03, -1.2501e-01,  4.4090e-04, -1.7927e-02,\n",
      "         -4.5233e-03, -6.0977e-03, -1.1764e-02, -6.8845e-04, -2.7917e-01,\n",
      "         -2.2906e-02, -7.0735e-02,  2.6088e-02, -3.2049e-02,  2.5730e-02,\n",
      "         -3.5854e-01, -1.2587e-01, -4.9601e-04,  1.4566e-02, -2.8728e-03,\n",
      "         -1.3600e-01, -9.8051e-02, -1.7359e-02, -3.6637e-03, -1.4126e-01,\n",
      "          3.5616e-05, -5.5491e-02,  1.1289e-02, -6.5611e-02,  5.5537e-03,\n",
      "         -4.3546e-03, -6.5648e-02, -2.4421e-02, -1.7524e-01, -5.0832e-02,\n",
      "          1.1401e-03,  1.8044e-02,  8.8742e-03,  4.8322e-03, -1.1999e-01,\n",
      "         -9.0838e-02, -7.1464e-02, -2.7454e-01, -1.8669e-03, -2.0111e-01,\n",
      "         -4.1075e-02, -1.6336e-01, -1.6198e-01, -2.9725e-01, -2.9629e-02,\n",
      "         -2.0483e-03, -2.1390e-02,  3.2464e-03,  2.1171e-03, -1.2622e-03,\n",
      "         -1.2863e-01,  2.5890e-02,  4.1677e-03, -5.8395e-05, -8.9311e-03,\n",
      "         -5.0514e-02, -5.8552e-02,  1.8378e-02, -3.3339e-02, -3.9251e-02],\n",
      "        [ 7.0016e-03, -1.4340e-02, -6.8543e-03,  3.6134e-02,  2.5893e-03,\n",
      "          2.2731e-02, -4.5312e-02, -7.4356e-04,  3.8213e-03, -9.5571e-03,\n",
      "         -8.8620e-03, -1.2770e-02, -4.1948e-04, -5.0822e-02, -1.9592e-02,\n",
      "         -6.7668e-04, -5.0252e-03,  2.2774e-02,  4.4796e-03, -1.9141e-02,\n",
      "          4.1593e-03,  2.6483e-03,  4.4486e-03, -6.6821e-03, -9.6024e-03,\n",
      "          1.2661e-03, -3.7811e-02,  3.4118e-03, -3.3107e-03, -3.0812e-03,\n",
      "          6.5340e-03, -1.6489e-02,  2.2115e-03,  2.5875e-02, -3.7479e-04,\n",
      "          8.7264e-03, -1.3017e-02,  1.2678e-02,  1.0124e-02, -5.7879e-02,\n",
      "          1.8838e-03, -4.5584e-03,  3.4528e-02, -2.8196e-02,  1.1930e-02,\n",
      "          8.9349e-03,  9.0064e-03, -1.2946e-02,  1.9368e-02, -4.3732e-02,\n",
      "          2.0900e-03,  5.8815e-03, -1.6206e-02,  5.5172e-03, -8.9009e-03,\n",
      "          5.5351e-03, -2.8819e-02,  8.9057e-04,  2.1145e-03, -5.3169e-03,\n",
      "          1.8871e-07,  9.8125e-04, -2.8880e-02, -1.4399e-02, -1.3624e-02,\n",
      "         -1.0231e-03,  8.0882e-03,  1.6421e-02, -2.2277e-02,  6.5028e-03,\n",
      "          8.4130e-05, -2.6556e-02, -1.9775e-03,  1.0209e-02,  4.8056e-03,\n",
      "          1.7249e-02, -9.2525e-03,  7.8662e-03,  2.3026e-04, -1.3539e-03,\n",
      "         -1.2408e-02,  3.0993e-03, -3.9512e-03,  1.5198e-02, -6.8985e-02,\n",
      "         -7.9226e-03,  2.6107e-02, -4.2146e-05, -6.6947e-04,  6.6524e-03,\n",
      "         -7.4992e-03, -7.0393e-03,  3.6786e-03, -8.2989e-06,  2.9045e-03,\n",
      "         -1.2260e-02, -1.3121e-02, -2.5915e-03, -2.9111e-02, -4.7574e-03],\n",
      "        [-4.8294e-03,  4.2308e-03, -3.3123e-04, -2.8802e-02, -1.1170e-02,\n",
      "         -1.2371e-02,  6.0676e-03,  7.3923e-03, -1.9684e-02, -4.1171e-03,\n",
      "          9.5540e-03,  3.1089e-03, -6.1454e-03, -1.3718e-02,  3.0219e-03,\n",
      "          2.2906e-03, -7.7658e-03, -2.9057e-02, -1.6742e-02,  2.5467e-03,\n",
      "         -7.7154e-03, -1.1813e-02, -1.4317e-03, -5.6428e-03, -1.1724e-02,\n",
      "          6.8956e-04, -3.2527e-02, -1.0053e-03,  2.4199e-03, -7.0990e-03,\n",
      "         -3.6520e-03, -1.5792e-02,  1.0409e-02, -2.0447e-02, -6.1729e-03,\n",
      "         -5.7748e-03, -2.2188e-02, -5.9927e-04,  5.6002e-06,  1.6791e-02,\n",
      "         -7.3010e-03,  1.9449e-03, -4.6228e-02,  2.3419e-02, -1.6374e-02,\n",
      "         -3.1285e-02, -2.6412e-02, -5.4728e-03, -4.5220e-02,  1.1480e-02,\n",
      "         -1.5595e-03,  4.9428e-03, -3.2013e-02, -2.4942e-02, -7.5962e-03,\n",
      "         -1.6318e-02, -2.5638e-02,  7.2026e-03, -1.8057e-02,  1.1906e-03,\n",
      "         -4.0165e-05,  8.1163e-04, -1.8280e-02,  1.4006e-03, -1.5663e-02,\n",
      "          1.1987e-02, -2.2944e-03, -2.4246e-02,  9.1816e-03, -6.1747e-04,\n",
      "          9.9753e-04,  6.7317e-03, -2.1691e-02, -3.2659e-02, -2.2744e-02,\n",
      "         -4.9993e-02,  4.9114e-03, -3.6866e-02, -2.4361e-04,  2.4009e-03,\n",
      "         -5.6452e-03, -1.0832e-02, -5.6461e-03, -4.3020e-02, -1.4606e-04,\n",
      "          1.2773e-02, -5.0724e-02, -3.9331e-03,  5.0323e-03, -8.6485e-03,\n",
      "         -3.8097e-02,  2.1848e-02,  2.6213e-03,  4.6330e-05, -1.5562e-03,\n",
      "         -3.4130e-02, -1.3521e-02, -8.8125e-03, -9.9538e-04, -3.1819e-02],\n",
      "        [-3.5621e-02, -3.0596e-02, -1.5341e-01, -6.2240e-02,  8.1729e-04,\n",
      "         -3.8645e-02, -3.2358e-02, -8.5125e-02, -2.4496e-02, -1.4144e-01,\n",
      "         -5.1516e-02, -2.0566e-01, -1.0968e-01, -4.8486e-02, -2.5047e-01,\n",
      "         -4.5122e-02, -1.6672e-01, -1.4619e-02, -2.1559e-04, -4.8702e-02,\n",
      "         -2.5659e-02, -1.3874e-03, -8.5486e-02, -8.9108e-02, -3.6038e-02,\n",
      "         -1.3436e-03, -1.3447e-01, -2.2152e-02, -3.5585e-02, -2.0356e-02,\n",
      "         -1.3995e-01, -9.7054e-02, -6.1748e-02, -4.1784e-02, -9.3397e-02,\n",
      "         -3.5478e-02, -1.8093e-02, -1.3253e-01, -1.9188e-02, -7.5774e-04,\n",
      "         -1.5946e-03, -1.5924e-03, -2.8684e-02,  4.7497e-03, -2.0968e-01,\n",
      "         -9.2592e-03, -2.0675e-02, -2.6130e-02, -5.9180e-02, -1.6319e-01,\n",
      "         -2.1698e-01, -1.4410e-01, -4.2990e-03, -2.9491e-02, -1.6674e-03,\n",
      "         -1.8424e-01, -4.5687e-02, -5.1460e-02, -7.2506e-03, -1.2127e-01,\n",
      "          2.0372e-06, -1.4345e-01, -3.8193e-02, -1.7667e-01,  6.1155e-03,\n",
      "         -3.1137e-02, -6.6531e-02,  1.0903e-03, -1.3065e-01, -3.7826e-04,\n",
      "         -2.6095e-03, -1.0361e-02, -3.5112e-03, -4.3932e-02, -5.0381e-02,\n",
      "         -2.5672e-02, -4.5139e-02, -1.0535e-01,  1.4387e-04, -1.6525e-01,\n",
      "         -1.7348e-02, -1.3836e-01, -1.0988e-01, -6.2468e-02,  1.1926e-02,\n",
      "          4.2901e-03, -6.8020e-03, -2.7766e-03, -2.3759e-02, -4.4654e-03,\n",
      "         -2.2245e-01, -1.1151e-01, -9.3929e-04, -3.5722e-05, -2.3161e-04,\n",
      "         -4.4093e-02, -6.4768e-02, -1.7818e-01,  7.0014e-03, -1.0381e-01],\n",
      "        [ 1.2151e-02, -5.4392e-04, -3.2524e-02, -1.3371e-02,  2.2003e-03,\n",
      "         -8.3598e-03,  4.3246e-02,  3.1375e-02,  4.5663e-03,  3.1993e-02,\n",
      "          1.4338e-02,  4.8379e-02,  2.6330e-02,  1.3377e-02,  3.6923e-02,\n",
      "          4.1866e-03,  2.0172e-02,  1.1321e-04,  9.6570e-03, -1.3363e-02,\n",
      "          1.4243e-02,  6.3260e-03, -2.5236e-02, -7.2815e-03,  8.2545e-03,\n",
      "          1.8109e-03,  5.2118e-02, -7.6412e-03,  1.3694e-02, -8.3402e-03,\n",
      "          4.3657e-02,  2.7157e-02,  5.1989e-03, -1.3320e-02,  1.3672e-02,\n",
      "         -1.9317e-02,  4.3367e-03, -6.9743e-03,  4.4809e-03, -2.7929e-02,\n",
      "         -2.4168e-03,  5.3648e-03, -1.7002e-02, -1.7345e-02,  3.3165e-02,\n",
      "         -4.8462e-02, -8.4519e-03,  1.8463e-02, -3.3872e-02,  6.4267e-02,\n",
      "          2.6241e-02,  3.4710e-02, -1.8064e-02,  1.6920e-02, -2.6116e-02,\n",
      "          2.3911e-02, -4.2279e-02,  1.3810e-02, -4.9265e-03, -2.6649e-02,\n",
      "         -2.7316e-07,  1.0391e-02,  3.9214e-03,  4.9333e-02,  6.4807e-03,\n",
      "         -7.0461e-03, -2.0247e-03, -3.9801e-02,  2.9059e-02, -3.2734e-02,\n",
      "          6.9744e-05, -4.4873e-02,  4.9062e-04,  1.5560e-02,  2.1024e-02,\n",
      "         -4.6169e-03, -7.5049e-03,  2.1454e-02,  7.1098e-04,  5.0090e-02,\n",
      "         -2.3735e-02,  1.9712e-02, -2.9588e-02, -2.3494e-02, -4.8804e-02,\n",
      "         -8.5823e-03, -5.2100e-02, -9.6912e-03,  1.2163e-02,  2.4958e-03,\n",
      "         -1.2450e-02,  1.9469e-02, -3.3636e-03, -2.8366e-05, -4.3716e-03,\n",
      "         -4.2554e-02, -5.2520e-03,  1.3462e-03, -4.9609e-03,  1.3589e-02]])}, 5: {'momentum_buffer': tensor([ 0.0529, -0.0220,  0.0072,  0.1396,  0.0215, -0.0863, -0.0012, -0.0075,\n",
      "        -0.0985, -0.0055])}}\n",
      "param_groups\n",
      "[{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_root, train_batch_size, test_batch_size):\n",
    "    mean, std_dev = [0.1307], [0.3081]\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std_dev)\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std_dev)\n",
    "    ])\n",
    "    trainset = MNIST(\n",
    "        data_root, train=True, download=True,\n",
    "        transform=transform_train\n",
    "    )\n",
    "    trainset = Subset(trainset, range(20000))\n",
    "    testset = MNIST(\n",
    "        data_root, train=False, download=True,\n",
    "        transform=transform_test\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        trainset, train_batch_size, shuffle=False,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        testset, test_batch_size, shuffle=False,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "class AvgMetric(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "        self.accumulator = 0.0\n",
    "        self.value = 0.0\n",
    "\n",
    "    def update(self, value, n):\n",
    "        self.value = value\n",
    "        self.counter += n\n",
    "        self.accumulator += value\n",
    "\n",
    "    def result(self):\n",
    "        return self.accumulator / self.counter\n",
    "\n",
    "\n",
    "class LeNet_300_100(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet_300_100, self).__init__()\n",
    "        self.linear0 = nn.Linear(28*28, 300)\n",
    "        self.relu0 = nn.ReLU(inplace=True)\n",
    "        self.linear1 = nn.Linear(300, 100)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu0(self.linear0(x))\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(epochs):\n",
    "    loss_metric = AvgMetric()\n",
    "    for epoch in range(epochs):\n",
    "        for step, (inputs, targets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()  # backprop\n",
    "            optimizer.step() # update params\n",
    "            loss_metric.update(loss, inputs.shape[0])\n",
    "\n",
    "            if (step+1) % 200 == 0:\n",
    "                print(\"Epoch[{}/{}], step[{}/{}]:\\tLoss={:.4f}\".format(\n",
    "                    epoch+1, epochs, step+1,\n",
    "                    len(train_loader.dataset) // train_batch_size,\n",
    "                    loss_metric.result()\n",
    "                ))\n",
    "\n",
    "\n",
    "train_batch_size, test_batch_size = 32, 16\n",
    "data_root = \"../../../../data/torchvision\"\n",
    "train_loader, test_loader = load_data(\n",
    "    data_root, train_batch_size, test_batch_size\n",
    ")\n",
    "model = LeNet_300_100()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train(2)\n",
    "\n",
    "print(\"==> Model's state_dict:\")\n",
    "for name, param in model.state_dict().items():\n",
    "    print(name, param.shape, sep=\"\\t\")\n",
    "print(\"\\n\\n==> Optimizer's state_dict:\")\n",
    "for name, param in optimizer.state_dict().items():\n",
    "    print(name, param, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "olive-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(torch.tensor([1, 2, 3]), torch.Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-employment",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "PyTorch 中有两种方法可以对模型进行保存和加载；一种是`torch.save()`函数保存和`torch.load()`函数加载`state_dict`；另一种方式则是借助 Python 的 pickle 库来保存和加载整个模型；\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Saving and Loading the Entire Model\n",
    "利用`torch.save()`和`torch.load()`函数便可实现对模型的加载和保存；这种方式简单且易于实现，然而缺点在于，由于 pickle 库并不保存模型类本身，而是保存定义了模型的类所在的文件的路径，即序列化的数据是与保存模型时特定的类和特定的目录结构，进而如果在其他项目中使用该模型或在重构代码或路径之后再进行模型导入时，代码可能会以多种方式中断；保存和加载的示例如下：\n",
    "\n",
    "```python\n",
    "model = LeNet_300_100()\n",
    "ckpt_path = \".../entire_model.pt\"\n",
    "torch.save(net, ckpt_path)\n",
    "model = torch.load(ckpt_path)\n",
    "```\n",
    "PyTorch 中约定使用`.pt`或`.pth`作为文件扩展名来保存模型；\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The `state_dict` in PyTorch\n",
    "在 PyTorch 中，一个模型的`state_dict`是其内部每个层的名称映射至相应参数的字典；只有一个层的可学习参数或注册缓冲区 (如 BN 的 `running_mean`) 会记录在`state_dict`中；此外，优化器也含有`state_dict`，其包含了优化器的状态信息以及所使用的超参数；\n",
    "\n",
    "```python\n",
    "class LeNet_300_100(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet_300_100, self).__init__()\n",
    "        self.linear0 = nn.Linear(28*28, 300)\n",
    "        self.relu0 = nn.ReLU(inplace=True)\n",
    "        self.linear1 = nn.Linear(300, 100)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu0(self.linear0(x))\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet_300_100()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "for name, param in model.state_dict().items():\n",
    "    print(name, \"\\t\", param.shape)\n",
    "\"\"\" ==>\n",
    "linear0.weight\ttorch.Size([300, 784])\n",
    "linear0.bias\ttorch.Size([300])\n",
    "linear1.weight\ttorch.Size([100, 300])\n",
    "linear1.bias\ttorch.Size([100])\n",
    "linear2.weight\ttorch.Size([10, 100])\n",
    "linear2.bias\ttorch.Size([10])\n",
    "\"\"\"\n",
    "```\n",
    "利用`state_dict`加载和保存模型的优点在于的灵活性更高；而缺点在于所加载的`state_dict`为字典类型，进而只能适用于原代码所定义的模型，或参数名称与参数形状完全与原模型相同的情况，否则便无法将`state_dict`导入模型；\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Saving and Loading a model `state_dict`\n",
    "对`state_dict`的保存依旧是使用`torch.save()`函数，加载则利用`torch.load()`方法加载`state_dict`，再利用模型的`load_state_dict`方法将`state_dict`导入至模型中；需要说明的是，由于仅对模型的`state_dict`进行了保存，进而加载得到的模型不含有任何与训练参数有关的信息，此时只能将模型用于推断、重新训练或微调；\n",
    "```python\n",
    "model = LeNet_300_100()\n",
    "ckpt_path = \".../state_dict_model.pt\"\n",
    "torch.save(net.state_dict(), ckpt_path)  # save the model\n",
    "model.load_state_dict(state_dict)        # load the model\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Saving and Loading for Resuming Training\n",
    "如果需要加载模型并恢复之前的训练，应在保存检查点时将优化器的`state_dict`以及其他需要保存的参数连同模型的`state_dict`一同进行保存；具体而言，只需将这些要保存的对象组织成一个字典，再将其传递给`torch.save()`函数即可，示例如下：\n",
    "```python\n",
    "# save\n",
    "model = LeNet_300_100()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "state_dict = {\n",
    "    'epoch': 5,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': 0.4,\n",
    "}\n",
    "ckpt_path = \"model.pt\"\n",
    "torch.save(state_dict, ckpt_path)\n",
    "\n",
    "# load\n",
    "model = LeNet_300_100()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "ckpt = torch.load(PATH)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "epoch = ckpt['epoch']\n",
    "loss = ckpt['loss']\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Saving and Loading Multiple Models in One File\n",
    "对于 GAN、seq2seq 模型、集成模型等在保存时需要保存多个`nn.Module`的模型，只需将需要保存的模型的`state_dict`、相应优化器的`state_dict`、以及其他需要保存的参数编写入字典，再利用`torch.save()`进行保存即可；加载时只需利用键值进行索引即可；示例如下\n",
    "```python\n",
    "# ==> save\n",
    "modelA = LeNet_300_100()\n",
    "modelB = LeNet_300_100()\n",
    "optimizerA = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerB = optim.SGD(modelB.parameters(), lr=0.001, momentum=0.9)\n",
    "ckpt_path = \".../multimodel.pt\"\n",
    "state_dict = {\n",
    "    'modelA_state_dict': modelA.state_dict(),\n",
    "    'modelB_state_dict': modelB.state_dict(),\n",
    "    'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "    'optimizerB_state_dict': optimizerB.state_dict()\n",
    "}\n",
    "torch.save(state_dict, ckpt_path)\n",
    "\n",
    "# ==> Load multiple models\n",
    "modelA = LeNet_300_100()\n",
    "modelB = LeNet_300_100()\n",
    "optimModelA = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)\n",
    "optimModelB = optim.SGD(modelB.parameters(), lr=0.001, momentum=0.9)\n",
    "ckpt = torch.load(ckpt_path)\n",
    "modelA.load_state_dict(ckpt['modelA_state_dict'])\n",
    "modelB.load_state_dict(ckpt['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(ckpt['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(ckpt['optimizerB_state_dict'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-sequence",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
