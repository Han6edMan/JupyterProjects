{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.transforms\n",
    "\n",
    "**PACKAGE**\n",
    "\n",
    "    _functional_video\n",
    "    _transforms_video\n",
    "    functional\n",
    "    functional_pil\n",
    "    functional_tensor\n",
    "    transforms\n",
    "\n",
    "**CLASSES**\n",
    "\n",
    "    Compose\n",
    "    ToTensor\n",
    "    PILToTensor\n",
    "    ConvertImageDtype\n",
    "    ToPILImage\n",
    "    Normalize\n",
    "    \n",
    "    Resize\n",
    "    Scale\n",
    "    CenterCrop\n",
    "    Pad\n",
    "    Lambda\n",
    "    RandomApply\n",
    "    RandomChoice\n",
    "    RandomOrder\n",
    "    RandomCrop\n",
    "    RandomHorizontalFlip\n",
    "    RandomVerticalFlip\n",
    "    RandomResizedCrop\n",
    "    RandomSizedCrop\n",
    "    FiveCrop\n",
    "    TenCrop\n",
    "    LinearTransformation\n",
    "    ColorJitter\n",
    "    RandomRotation\n",
    "    RandomAffine\n",
    "    Grayscale\n",
    "    RandomGrayscale\n",
    "    RandomPerspective\n",
    "    RandomErasing\n",
    "    GaussianBlur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.Compose\n",
    "`transforms.Compose(transforms)`\n",
    "\n",
    "`transforms`应为`transform`组成的列表，其每个元素为对每条数据施加的操作，这个类则用于讲这些`transform`组合起来；\n",
    "\n",
    "**File**:  \\torchvision\\transforms\\transforms.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.ToTensor()\n",
    "\n",
    "若`PIL`图像为 (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) 中的一种，则可以将其转换为像素值在 $[0.0, 1.0]$ 范围的 $C\\times H\\times W$ 的`torch.FloatTensor`；若一个 NumPy 数组像素值在$[0, 255]$ 范围之间、形状为 $H\\times W\\times C$、数据类型为`np.unit8`，则也可以将其转换成一个像素值在 $[0.0, 1.0]$ 范围的 $C\\times H\\times W$ 的`torch.FloatTensor`；其他情况则返回一个像素值没有经过放缩的张量；\n",
    "\n",
    "需要注意的是，由于输入数据会被缩放到 $[0.0,1.0]$ 之间，进而不应对目标图像使用这个转换；更多实现图像掩码 (target image masks) 转换的内容参见[这里](https://github.com/pytorch/vision/tree/master/references/segmentation)\n",
    "\n",
    "这个转换不支持 torchscipt；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    PILToTensor\n",
    "    ConvertImageDtype\n",
    "    ToPILImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.Normalize()\n",
    "`transforms(mean, std, inplace=False)`\n",
    "\n",
    "对图像在每个通道上进行归一化，其中`mean`、`std`均为长度为 C 的一维序列，C为通道数；即执行操作``img[C] = (img[C] - mean[C]) / std[C]``；`inplace=False`时该函数不会改变原图像\n",
    "\n",
    "**File**:   \\torchvision\\transforms\\transforms.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.Resize()\n",
    "`transforms.Resize(size, interpolation=2)`\n",
    "    \n",
    "对输入的 PIL 图像或张量进行放缩；\n",
    "\n",
    "**Args**\n",
    "- size: 输出图像大小；若`size`被指定为类似`(h, w)`的序列，则输出图像即为如此；若其被指定为单个整数，则默认以图像较短的那个边与其匹配，即假若图像的高大于宽，则返回图像形状为`(size * height / width, size)`；`torchscript`模式不支持指定单个整数，此时应使用长度为 1 的元组或列表，例如`[size,]`；\n",
    "\n",
    "- interpolation: 整型；由[`filters`](https://pillow.readthedocs.io/en/latest/handbook/concepts.html#filters)定义的代表差值方式的`enum`；默认为``PIL.Image.BILINEAR``；输入为张量时只支持``PIL.Image.NEAREST``、``PIL.Image.BILINEAR``、``PIL.Image.BICUBIC``\n",
    "\n",
    "**File**:        \\torchvision\\transforms\\transforms.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.RandomCrop\n",
    "```py\n",
    "transforms.RandomCrop(\n",
    "    size,\n",
    "    padding=None,\n",
    "    pad_if_needed=False,\n",
    "    fill=0,\n",
    "    padding_mode='constant'\n",
    ")\n",
    "```\n",
    "  \n",
    "**Docstring**\n",
    "\n",
    "将给定的 PIL 图像或张量依据`size`在随机位置根据给定的大小进行裁剪\n",
    "\n",
    "**Args**\n",
    "\n",
    "- size: 裁剪后输出的形状；当被指定为一整数时，输出形状为` (size, size)`；当被指定为一序列`(h, w)`时，输出形状即为所指定；当被指定为长度为 1 的列表或元祖时，该元素作为输出图像的宽和高；\n",
    "- padding: 默认 None；若其值为 4 元序列，则序列元素分别分配至图像左、上、右、下侧的填充值；若其值为 2 元序列，则序列元素分别分配至图像水平和竖直方向的填充值；若其值为一整数，略；`torchscript`模式不支持单个整数，进而应传递`[padding, ]`\n",
    "- pad_if_needed: 当输入图像形状小于输出时会填充图片，防止报错；由于裁剪是在填充之后进行的，进而填充可以视为对原图像上进行了随机的偏移；\n",
    "- fill: 填充模式为常数时的填充值，默认为 0；若为3元数组，则分别填充至 R, G, B 通道中；仅在`padding_mode`为`constant`时起作用；\n",
    "- padding_mode: 填充模式，包括`constant`, `edge`, `reflect`, `symmetric`，默认`constant`\n",
    "    - constant: 利用由`fill`给定的值填充；\n",
    "    - edge: 由图像边缘最后一个像素点的取值进行填充；    \n",
    "    - reflect: 根据图像像素点取值，以**不重复**边缘像素点取值的方式对称地填充，如像素点为 $[1, 2, 3, 4]$，则填充 2 个元素的情况下填充结果为 $[3, 2, 1, 2, 3, 4, 3, 2]$；\n",
    "    - symmetric: 根据图像像素点取值，以**重复**边缘像素点取值的方式对称地填充，如像素点为 $[1, 2, 3, 4]$，则填充 2 个元素的情况下填充结果为 $[2, 1, 1, 2, 3, 4, 4, 3]$；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.RandomResizedCrop()\n",
    "```py\n",
    "transforms.RandomResizedCrop(\n",
    "    size,\n",
    "    scale=(0.08, 1.0),\n",
    "    ratio=(0.75, 1.3333333333333333),\n",
    "    interpolation=2,\n",
    ")\n",
    "```\n",
    "**Docstring**\n",
    "\n",
    "对于给定的 PIL 图像，以原始大小的随机大小和原始高宽比的随机高宽比进行裁剪，裁剪结果最终会调整到给定的大小，其常用于训练 Inception 网络\n",
    "\n",
    "**Args**\n",
    "- size: 略\n",
    "- scale: 原始图像被裁剪的范围\n",
    "- ratio: 原长高比被裁剪的范围\n",
    "- interpolation: 默认为`PIL.Image.BILINEAR`\n",
    "\n",
    "**File**:       \\torchvision\\transforms\\transforms.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
