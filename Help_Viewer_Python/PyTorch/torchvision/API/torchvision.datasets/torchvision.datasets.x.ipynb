{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torchvision.datasets in torchvision:\n",
      "\n",
      "NAME\n",
      "    torchvision.datasets\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    caltech\n",
      "    celeba\n",
      "    cifar\n",
      "    cityscapes\n",
      "    coco\n",
      "    fakedata\n",
      "    flickr\n",
      "    folder\n",
      "    hmdb51\n",
      "    imagenet\n",
      "    kinetics\n",
      "    lsun\n",
      "    mnist\n",
      "    omniglot\n",
      "    phototour\n",
      "    places365\n",
      "    samplers (package)\n",
      "    sbd\n",
      "    sbu\n",
      "    semeion\n",
      "    stl10\n",
      "    svhn\n",
      "    ucf101\n",
      "    usps\n",
      "    utils\n",
      "    video_utils\n",
      "    vision\n",
      "    voc\n",
      "\n",
      "CLASSES\n",
      "    torch.utils.data.dataset.Dataset(typing.Generic)\n",
      "        torchvision.datasets.vision.VisionDataset\n",
      "            torchvision.datasets.caltech.Caltech101\n",
      "            torchvision.datasets.caltech.Caltech256\n",
      "            torchvision.datasets.celeba.CelebA\n",
      "            torchvision.datasets.cifar.CIFAR10\n",
      "                torchvision.datasets.cifar.CIFAR100\n",
      "            torchvision.datasets.cityscapes.Cityscapes\n",
      "            torchvision.datasets.coco.CocoCaptions\n",
      "            torchvision.datasets.coco.CocoDetection\n",
      "            torchvision.datasets.fakedata.FakeData\n",
      "            torchvision.datasets.flickr.Flickr30k\n",
      "            torchvision.datasets.flickr.Flickr8k\n",
      "            torchvision.datasets.folder.DatasetFolder\n",
      "                torchvision.datasets.folder.ImageFolder\n",
      "                    torchvision.datasets.imagenet.ImageNet\n",
      "            torchvision.datasets.hmdb51.HMDB51\n",
      "            torchvision.datasets.kinetics.Kinetics400\n",
      "            torchvision.datasets.lsun.LSUN\n",
      "            torchvision.datasets.lsun.LSUNClass\n",
      "            torchvision.datasets.mnist.MNIST\n",
      "                torchvision.datasets.mnist.EMNIST\n",
      "                torchvision.datasets.mnist.FashionMNIST\n",
      "                torchvision.datasets.mnist.KMNIST\n",
      "                torchvision.datasets.mnist.QMNIST\n",
      "            torchvision.datasets.omniglot.Omniglot\n",
      "            torchvision.datasets.phototour.PhotoTour\n",
      "            torchvision.datasets.places365.Places365\n",
      "            torchvision.datasets.sbd.SBDataset\n",
      "            torchvision.datasets.sbu.SBU\n",
      "            torchvision.datasets.semeion.SEMEION\n",
      "            torchvision.datasets.stl10.STL10\n",
      "            torchvision.datasets.svhn.SVHN\n",
      "            torchvision.datasets.ucf101.UCF101\n",
      "            torchvision.datasets.usps.USPS\n",
      "            torchvision.datasets.voc.VOCDetection\n",
      "            torchvision.datasets.voc.VOCSegmentation\n",
      "    \n",
      "    class CIFAR10(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CIFAR10(*args, **kwds)\n",
      "     |  \n",
      "     |  `CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
      "     |      train (bool, optional): If True, creates dataset from training set, otherwise\n",
      "     |          creates from test set.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CIFAR10\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'cifar-10-batches-py'\n",
      "     |  \n",
      "     |  filename = 'cifar-10-python.tar.gz'\n",
      "     |  \n",
      "     |  meta = {'filename': 'batches.meta', 'key': 'label_names', 'md5': '5ff9...\n",
      "     |  \n",
      "     |  test_list = [['test_batch', '40351d587109b95175f43aff81a1287e']]\n",
      "     |  \n",
      "     |  tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
      "     |  \n",
      "     |  train_list = [['data_batch_1', 'c99cafc152244af753f735de768cd75f'], ['...\n",
      "     |  \n",
      "     |  url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CIFAR100(CIFAR10)\n",
      "     |  CIFAR100(*args, **kwds)\n",
      "     |  \n",
      "     |  `CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
      "     |  \n",
      "     |  This is a subclass of the `CIFAR10` Dataset.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CIFAR100\n",
      "     |      CIFAR10\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'cifar-100-python'\n",
      "     |  \n",
      "     |  filename = 'cifar-100-python.tar.gz'\n",
      "     |  \n",
      "     |  meta = {'filename': 'meta', 'key': 'fine_label_names', 'md5': '7973b15...\n",
      "     |  \n",
      "     |  test_list = [['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc']]\n",
      "     |  \n",
      "     |  tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
      "     |  \n",
      "     |  train_list = [['train', '16019d7e3df5f24257cddd939b257f8d']]\n",
      "     |  \n",
      "     |  url = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CIFAR10:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Caltech101(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Caltech101(*args, **kwds)\n",
      "     |  \n",
      "     |  `Caltech 101 <http://www.vision.caltech.edu/Image_Datasets/Caltech101/>`_ Dataset.\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``caltech101`` exists or will be saved to if download is set to True.\n",
      "     |      target_type (string or list, optional): Type of target to use, ``category`` or\n",
      "     |      ``annotation``. Can also be a list to output a tuple with all specified target types.\n",
      "     |      ``category`` represents the target class, and ``annotation`` is a list of points\n",
      "     |      from a hand-generated outline. Defaults to ``category``.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Caltech101\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where the type of target specified by target_type.\n",
      "     |  \n",
      "     |  __init__(self, root: str, target_type: Union[List[str], str] = 'category', transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Caltech256(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Caltech256(*args, **kwds)\n",
      "     |  \n",
      "     |  `Caltech 256 <http://www.vision.caltech.edu/Image_Datasets/Caltech256/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``caltech256`` exists or will be saved to if download is set to True.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Caltech256\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CelebA(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CelebA(*args, **kwds)\n",
      "     |  \n",
      "     |  `Large-scale CelebFaces Attributes (CelebA) Dataset <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      split (string): One of {'train', 'valid', 'test', 'all'}.\n",
      "     |          Accordingly dataset is selected.\n",
      "     |      target_type (string or list, optional): Type of target to use, ``attr``, ``identity``, ``bbox``,\n",
      "     |          or ``landmarks``. Can also be a list to output a tuple with all specified target types.\n",
      "     |          The targets represent:\n",
      "     |              ``attr`` (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes\n",
      "     |              ``identity`` (int): label for each person (data points with the same identity are the same person)\n",
      "     |              ``bbox`` (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)\n",
      "     |              ``landmarks`` (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,\n",
      "     |                  righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)\n",
      "     |          Defaults to ``attr``. If empty, ``None`` will be returned as target.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.ToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CelebA\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', target_type: Union[List[str], str] = 'attr', transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'celeba'\n",
      "     |  \n",
      "     |  file_list = [('0B7EVK8r0v71pZjFTYXZWM3FlRnM', '00d2c5bc6d35e252742224a...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Cityscapes(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Cityscapes(*args, **kwds)\n",
      "     |  \n",
      "     |  `Cityscapes <http://www.cityscapes-dataset.com/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory ``leftImg8bit``\n",
      "     |          and ``gtFine`` or ``gtCoarse`` are located.\n",
      "     |      split (string, optional): The image split to use, ``train``, ``test`` or ``val`` if mode=\"fine\"\n",
      "     |          otherwise ``train``, ``train_extra`` or ``val``\n",
      "     |      mode (string, optional): The quality mode to use, ``fine`` or ``coarse``\n",
      "     |      target_type (string or list, optional): Type of target to use, ``instance``, ``semantic``, ``polygon``\n",
      "     |          or ``color``. Can also be a list to output a tuple with all specified target types.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |      Get semantic segmentation target\n",
      "     |  \n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          dataset = Cityscapes('./data/cityscapes', split='train', mode='fine',\n",
      "     |                               target_type='semantic')\n",
      "     |  \n",
      "     |          img, smnt = dataset[0]\n",
      "     |  \n",
      "     |      Get multiple targets\n",
      "     |  \n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          dataset = Cityscapes('./data/cityscapes', split='train', mode='fine',\n",
      "     |                               target_type=['instance', 'color', 'polygon'])\n",
      "     |  \n",
      "     |          img, (inst, col, poly) = dataset[0]\n",
      "     |  \n",
      "     |      Validate on the \"coarse\" set\n",
      "     |  \n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          dataset = Cityscapes('./data/cityscapes', split='val', mode='coarse',\n",
      "     |                               target_type='semantic')\n",
      "     |  \n",
      "     |          img, smnt = dataset[0]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Cityscapes\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is a tuple of all target types if target_type is a list with more\n",
      "     |          than one item. Otherwise target is a json object if target_type=\"polygon\", else the image segmentation.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', mode: str = 'fine', target_type: Union[List[str], str] = 'instance', transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, transforms: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CityscapesClass = <class 'torchvision.datasets.cityscapes.CityscapesCl...\n",
      "     |      CityscapesClass(name, id, train_id, category, category_id, has_instances, ignore_in_eval, color)\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = [CityscapesClass(name='unlabeled', id=0, train_id...nces=Fal...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CocoCaptions(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CocoCaptions(*args, **kwds)\n",
      "     |  \n",
      "     |  `MS Coco Captions <https://cocodataset.org/#captions-2015>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      annFile (string): Path to json annotation file.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.ToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |      .. code:: python\n",
      "     |  \n",
      "     |          import torchvision.datasets as dset\n",
      "     |          import torchvision.transforms as transforms\n",
      "     |          cap = dset.CocoCaptions(root = 'dir where images are',\n",
      "     |                                  annFile = 'json annotation file',\n",
      "     |                                  transform=transforms.ToTensor())\n",
      "     |  \n",
      "     |          print('Number of samples: ', len(cap))\n",
      "     |          img, target = cap[3] # load 4th sample\n",
      "     |  \n",
      "     |          print(\"Image Size: \", img.size())\n",
      "     |          print(target)\n",
      "     |  \n",
      "     |      Output: ::\n",
      "     |  \n",
      "     |          Number of samples: 82783\n",
      "     |          Image Size: (3L, 427L, 640L)\n",
      "     |          [u'A plane emitting smoke stream flying over a mountain.',\n",
      "     |          u'A plane darts across a bright blue sky behind a mountain covered in snow',\n",
      "     |          u'A plane leaves a contrail above the snowy mountain top.',\n",
      "     |          u'A mountain that has a plane flying overheard in the distance.',\n",
      "     |          u'A mountain view with a plume of smoke in the background']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CocoCaptions\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target). target is a list of captions for the image.\n",
      "     |  \n",
      "     |  __init__(self, root: str, annFile: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, transforms: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CocoDetection(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CocoDetection(*args, **kwds)\n",
      "     |  \n",
      "     |  `MS Coco Detection <https://cocodataset.org/#detection-2016>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      annFile (string): Path to json annotation file.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.ToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CocoDetection\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target). target is the object returned by ``coco.loadAnns``.\n",
      "     |  \n",
      "     |  __init__(self, root: str, annFile: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, transforms: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DatasetFolder(torchvision.datasets.vision.VisionDataset)\n",
      "     |  DatasetFolder(*args, **kwds)\n",
      "     |  \n",
      "     |  A generic data loader where the samples are arranged in this way: ::\n",
      "     |  \n",
      "     |      root/class_x/xxx.ext\n",
      "     |      root/class_x/xxy.ext\n",
      "     |      root/class_x/xxz.ext\n",
      "     |  \n",
      "     |      root/class_y/123.ext\n",
      "     |      root/class_y/nsdf3.ext\n",
      "     |      root/class_y/asd932_.ext\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory path.\n",
      "     |      loader (callable): A function to load a sample given its path.\n",
      "     |      extensions (tuple[string]): A list of allowed extensions.\n",
      "     |          both extensions and is_valid_file should not be passed.\n",
      "     |      transform (callable, optional): A function/transform that takes in\n",
      "     |          a sample and returns a transformed version.\n",
      "     |          E.g, ``transforms.RandomCrop`` for images.\n",
      "     |      target_transform (callable, optional): A function/transform that takes\n",
      "     |          in the target and transforms it.\n",
      "     |      is_valid_file (callable, optional): A function that takes path of a file\n",
      "     |          and check if the file is a valid file (used to check of corrupt files)\n",
      "     |          both extensions and is_valid_file should not be passed.\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class names sorted alphabetically.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      samples (list): List of (sample path, class_index) tuples\n",
      "     |      targets (list): The class_index value for each image in the dataset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, loader: Callable[[str], Any], extensions: Union[Tuple[str, ...], NoneType] = None, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, is_valid_file: Union[Callable[[str], bool], NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class EMNIST(MNIST)\n",
      "     |  EMNIST(*args, **kwds)\n",
      "     |  \n",
      "     |  `EMNIST <https://www.westernsydney.edu.au/bens/home/reproducible_research/emnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``EMNIST/processed/training.pt``\n",
      "     |          and  ``EMNIST/processed/test.pt`` exist.\n",
      "     |      split (string): The dataset has 6 different splits: ``byclass``, ``bymerge``,\n",
      "     |          ``balanced``, ``letters``, ``digits`` and ``mnist``. This argument specifies\n",
      "     |          which one to use.\n",
      "     |      train (bool, optional): If True, creates dataset from ``training.pt``,\n",
      "     |          otherwise from ``test.pt``.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the EMNIST data if it doesn't exist in processed_folder already.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes_split_dict = {'balanced': ['0', '1', '2', '3', '4', '5', '6', ...\n",
      "     |  \n",
      "     |  md5 = '58c8d27c78d21e728a6bc7b3cc06412e'\n",
      "     |  \n",
      "     |  splits = ('byclass', 'bymerge', 'balanced', 'letters', 'digits', 'mnis...\n",
      "     |  \n",
      "     |  url = 'http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', ...\n",
      "     |  \n",
      "     |  resources = [('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyt...\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FakeData(torchvision.datasets.vision.VisionDataset)\n",
      "     |  FakeData(*args, **kwds)\n",
      "     |  \n",
      "     |  A fake dataset that returns randomly generated images and returns them as PIL images\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      size (int, optional): Size of the dataset. Default: 1000 images\n",
      "     |      image_size(tuple, optional): Size if the returned images. Default: (3, 224, 224)\n",
      "     |      num_classes(int, optional): Number of classes in the datset. Default: 10\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      random_offset (int): Offsets the index-based random seed used to\n",
      "     |          generate each image. Default: 0\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FakeData\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, size: int = 1000, image_size: Tuple[int, int, int] = (3, 224, 224), num_classes: int = 10, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, random_offset: int = 0) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FashionMNIST(MNIST)\n",
      "     |  FashionMNIST(*args, **kwds)\n",
      "     |  \n",
      "     |  `Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``FashionMNIST/processed/training.pt``\n",
      "     |          and  ``FashionMNIST/processed/test.pt`` exist.\n",
      "     |      train (bool, optional): If True, creates dataset from ``training.pt``,\n",
      "     |          otherwise from ``test.pt``.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FashionMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'San...\n",
      "     |  \n",
      "     |  resources = [('http://fashion-mnist.s3-website.eu-central-1.amazonaws....\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the MNIST data if it doesn't exist in processed_folder already.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Flickr30k(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Flickr30k(*args, **kwds)\n",
      "     |  \n",
      "     |  `Flickr30k Entities <http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      ann_file (string): Path to annotation file.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.ToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Flickr30k\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target). target is a list of captions for the image.\n",
      "     |  \n",
      "     |  __init__(self, root: str, ann_file: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Flickr8k(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Flickr8k(*args, **kwds)\n",
      "     |  \n",
      "     |  `Flickr8k Entities <http://hockenmaier.cs.illinois.edu/8k-pictures.html>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      ann_file (string): Path to annotation file.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.ToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Flickr8k\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target). target is a list of captions for the image.\n",
      "     |  \n",
      "     |  __init__(self, root: str, ann_file: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class HMDB51(torchvision.datasets.vision.VisionDataset)\n",
      "     |  HMDB51(*args, **kwds)\n",
      "     |  \n",
      "     |  `HMDB51 <http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/>`_\n",
      "     |  dataset.\n",
      "     |  \n",
      "     |  HMDB51 is an action recognition video dataset.\n",
      "     |  This dataset consider every video as a collection of video clips of fixed size, specified\n",
      "     |  by ``frames_per_clip``, where the step in frames between each clip is given by\n",
      "     |  ``step_between_clips``.\n",
      "     |  \n",
      "     |  To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n",
      "     |  and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n",
      "     |  elements will come from video 1, and the next three elements from video 2.\n",
      "     |  Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n",
      "     |  frames in a video might be present.\n",
      "     |  \n",
      "     |  Internally, it uses a VideoClips object to handle clip creation.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the HMDB51 Dataset.\n",
      "     |      annotation_path (str): Path to the folder containing the split files.\n",
      "     |      frames_per_clip (int): Number of frames in a clip.\n",
      "     |      step_between_clips (int): Number of frames between each clip.\n",
      "     |      fold (int, optional): Which fold to use. Should be between 1 and 3.\n",
      "     |      train (bool, optional): If ``True``, creates a dataset from the train split,\n",
      "     |          otherwise from the ``test`` split.\n",
      "     |      transform (callable, optional): A function/transform that takes in a TxHxWxC video\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      video (Tensor[T, H, W, C]): the `T` video frames\n",
      "     |      audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n",
      "     |          and `L` is the number of points\n",
      "     |      label (int): class of the video clip\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HMDB51\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, root, annotation_path, frames_per_clip, step_between_clips=1, frame_rate=None, fold=1, train=True, transform=None, _precomputed_metadata=None, num_workers=1, _video_width=0, _video_height=0, _video_min_dimension=0, _audio_samples=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  metadata\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  TEST_TAG = 2\n",
      "     |  \n",
      "     |  TRAIN_TAG = 1\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  data_url = 'http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10...\n",
      "     |  \n",
      "     |  splits = {'md5': '15e67781e70dcfbdce2d7dbb9b3344b5', 'url': 'http://se...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ImageFolder(DatasetFolder)\n",
      "     |  ImageFolder(*args, **kwds)\n",
      "     |  \n",
      "     |  A generic data loader where the images are arranged in this way: ::\n",
      "     |  \n",
      "     |      root/dog/xxx.png\n",
      "     |      root/dog/xxy.png\n",
      "     |      root/dog/xxz.png\n",
      "     |  \n",
      "     |      root/cat/123.png\n",
      "     |      root/cat/nsdf3.png\n",
      "     |      root/cat/asd932_.png\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory path.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      loader (callable, optional): A function to load an image given its path.\n",
      "     |      is_valid_file (callable, optional): A function that takes path of an Image file\n",
      "     |          and check if the file is a valid file (used to check of corrupt files)\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class names sorted alphabetically.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      imgs (list): List of (image path, class_index) tuples\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ImageFolder\n",
      "     |      DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, loader: Callable[[str], Any] = <function default_loader at 0x000001B040B579D0>, is_valid_file: Union[Callable[[str], bool], NoneType] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DatasetFolder:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ImageNet(torchvision.datasets.folder.ImageFolder)\n",
      "     |  ImageNet(*args, **kwds)\n",
      "     |  \n",
      "     |  `ImageNet <http://image-net.org/>`_ 2012 Classification Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the ImageNet Dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``train``, or ``val``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      loader (callable, optional): A function to load an image given its path.\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class name tuples.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      wnids (list): List of the WordNet IDs.\n",
      "     |      wnid_to_idx (dict): Dict with items (wordnet_id, class_index).\n",
      "     |      imgs (list): List of (image path, class_index) tuples\n",
      "     |      targets (list): The class_index value for each image in the dataset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ImageNet\n",
      "     |      torchvision.datasets.folder.ImageFolder\n",
      "     |      torchvision.datasets.folder.DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', download: Union[str, NoneType] = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  parse_archives(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  split_folder\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.folder.DatasetFolder:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class KMNIST(MNIST)\n",
      "     |  KMNIST(*args, **kwds)\n",
      "     |  \n",
      "     |  `Kuzushiji-MNIST <https://github.com/rois-codh/kmnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``KMNIST/processed/training.pt``\n",
      "     |          and  ``KMNIST/processed/test.pt`` exist.\n",
      "     |      train (bool, optional): If True, creates dataset from ``training.pt``,\n",
      "     |          otherwise from ``test.pt``.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['o', 'ki', 'su', 'tsu', 'na', 'ha', 'ma', 'ya', 're', 'wo']\n",
      "     |  \n",
      "     |  resources = [('http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-imag...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the MNIST data if it doesn't exist in processed_folder already.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Kinetics400(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Kinetics400(*args, **kwds)\n",
      "     |  \n",
      "     |  `Kinetics-400 <https://deepmind.com/research/open-source/open-source-datasets/kinetics/>`_\n",
      "     |  dataset.\n",
      "     |  \n",
      "     |  Kinetics-400 is an action recognition video dataset.\n",
      "     |  This dataset consider every video as a collection of video clips of fixed size, specified\n",
      "     |  by ``frames_per_clip``, where the step in frames between each clip is given by\n",
      "     |  ``step_between_clips``.\n",
      "     |  \n",
      "     |  To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n",
      "     |  and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n",
      "     |  elements will come from video 1, and the next three elements from video 2.\n",
      "     |  Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n",
      "     |  frames in a video might be present.\n",
      "     |  \n",
      "     |  Internally, it uses a VideoClips object to handle clip creation.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Kinetics-400 Dataset.\n",
      "     |      frames_per_clip (int): number of frames in a clip\n",
      "     |      step_between_clips (int): number of frames between each clip\n",
      "     |      transform (callable, optional): A function/transform that  takes in a TxHxWxC video\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      video (Tensor[T, H, W, C]): the `T` video frames\n",
      "     |      audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n",
      "     |          and `L` is the number of points\n",
      "     |      label (int): class of the video clip\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Kinetics400\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, root, frames_per_clip, step_between_clips=1, frame_rate=None, extensions=('avi',), transform=None, _precomputed_metadata=None, num_workers=1, _video_width=0, _video_height=0, _video_min_dimension=0, _audio_samples=0, _audio_channels=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  metadata\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LSUN(torchvision.datasets.vision.VisionDataset)\n",
      "     |  LSUN(*args, **kwds)\n",
      "     |  \n",
      "     |  `LSUN <https://www.yf.io/p/lsun>`_ dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory for the database files.\n",
      "     |      classes (string or list): One of {'train', 'val', 'test'} or a list of\n",
      "     |          categories to load. e,g. ['bedroom_train', 'church_outdoor_train'].\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSUN\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target) where target is the index of the target category.\n",
      "     |  \n",
      "     |  __init__(self, root: str, classes: Union[str, List[str]] = 'train', transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LSUNClass(torchvision.datasets.vision.VisionDataset)\n",
      "     |  LSUNClass(*args, **kwds)\n",
      "     |  \n",
      "     |  An abstract class representing a :class:`Dataset`.\n",
      "     |  \n",
      "     |  All datasets that represent a map from keys to data samples should subclass\n",
      "     |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "     |  data sample for a given key. Subclasses could also optionally overwrite\n",
      "     |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      "     |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "     |  of :class:`~torch.utils.data.DataLoader`.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      "     |    sampler that yields integral indices.  To make it work with a map-style\n",
      "     |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSUNClass\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class MNIST(torchvision.datasets.vision.VisionDataset)\n",
      "     |  MNIST(*args, **kwds)\n",
      "     |  \n",
      "     |  `MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
      "     |          and  ``MNIST/processed/test.pt`` exist.\n",
      "     |      train (bool, optional): If True, creates dataset from ``training.pt``,\n",
      "     |          otherwise from ``test.pt``.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the MNIST data if it doesn't exist in processed_folder already.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', ...\n",
      "     |  \n",
      "     |  resources = [('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyt...\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Omniglot(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Omniglot(*args, **kwds)\n",
      "     |  \n",
      "     |  `Omniglot <https://github.com/brendenlake/omniglot>`_ Dataset.\n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``omniglot-py`` exists.\n",
      "     |      background (bool, optional): If True, creates dataset from the \"background\" set, otherwise\n",
      "     |          creates from the \"evaluation\" set. This terminology is defined by the authors.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset zip files from the internet and\n",
      "     |          puts it in root directory. If the zip files are already downloaded, they are not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Omniglot\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target character class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, background: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  download_url_prefix = 'https://github.com/brendenlake/omniglot/raw/mas...\n",
      "     |  \n",
      "     |  folder = 'omniglot-py'\n",
      "     |  \n",
      "     |  zips_md5 = {'images_background': '68d2efa1b9178cc56df9314c21c6e718', '...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PhotoTour(torchvision.datasets.vision.VisionDataset)\n",
      "     |  PhotoTour(*args, **kwds)\n",
      "     |  \n",
      "     |  `Learning Local Image Descriptors Data <http://phototour.cs.washington.edu/patches/default.htm>`_ Dataset.\n",
      "     |  \n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are.\n",
      "     |      name (string): Name of the dataset to load.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PhotoTour\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Union[torch.Tensor, Tuple[Any, Any, torch.Tensor]]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (data1, data2, matches)\n",
      "     |  \n",
      "     |  __init__(self, root: str, name: str, train: bool = True, transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  image_ext = 'bmp'\n",
      "     |  \n",
      "     |  info_file = 'info.txt'\n",
      "     |  \n",
      "     |  lens = {'liberty': 450092, 'liberty_harris': 379587, 'notredame': 4681...\n",
      "     |  \n",
      "     |  matches_files = 'm50_100000_100000_0.txt'\n",
      "     |  \n",
      "     |  means = {'liberty': 0.4437, 'liberty_harris': 0.4437, 'notredame': 0.4...\n",
      "     |  \n",
      "     |  stds = {'liberty': 0.2019, 'liberty_harris': 0.2019, 'notredame': 0.18...\n",
      "     |  \n",
      "     |  urls = {'liberty': ['http://icvl.ee.ic.ac.uk/vbalnt/liberty.zip', 'lib...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Places365(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Places365(*args, **kwds)\n",
      "     |  \n",
      "     |  `Places365 <http://places2.csail.mit.edu/index.html>`_ classification dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Places365 dataset.\n",
      "     |      split (string, optional): The dataset split. Can be one of ``train-standard`` (default), ``train-challendge``,\n",
      "     |          ``val``.\n",
      "     |      small (bool, optional): If ``True``, uses the small images, i. e. resized to 256 x 256 pixels, instead of the\n",
      "     |          high resolution ones.\n",
      "     |      download (bool, optional): If ``True``, downloads the dataset components and places them in ``root``. Already\n",
      "     |          downloaded archives are not downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      loader (callable, optional): A function to load an image given its path.\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class names.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      imgs (list): List of (image path, class_index) tuples\n",
      "     |      targets (list): The class_index value for each image in the dataset\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |      RuntimeError: If ``download is False`` and the meta files, i. e. the devkit, are not present or corrupted.\n",
      "     |      RuntimeError: If ``download is True`` and the image archive is already extracted.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Places365\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train-standard', small: bool = False, download: bool = False, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, loader: Callable[[str], Any] = <function default_loader at 0x000001B040B579D0>) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download_devkit(self) -> None\n",
      "     |  \n",
      "     |  download_images(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  load_categories(self, download: bool = True) -> Tuple[List[str], Dict[str, int]]\n",
      "     |  \n",
      "     |  load_file_list(self, download: bool = True) -> Tuple[List[Tuple[str, int]], List[int]]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  images_dir\n",
      "     |  \n",
      "     |  variant\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class QMNIST(MNIST)\n",
      "     |  QMNIST(*args, **kwds)\n",
      "     |  \n",
      "     |  `QMNIST <https://github.com/facebookresearch/qmnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset whose ``processed''\n",
      "     |          subdir contains torch binary files with the datasets.\n",
      "     |      what (string,optional): Can be 'train', 'test', 'test10k',\n",
      "     |          'test50k', or 'nist' for respectively the mnist compatible\n",
      "     |          training set, the 60k qmnist testing set, the 10k qmnist\n",
      "     |          examples that match the mnist testing set, the 50k\n",
      "     |          remaining qmnist testing examples, or all the nist\n",
      "     |          digits. The default is to select 'train' or 'test'\n",
      "     |          according to the compatibility argument 'train'.\n",
      "     |      compat (bool,optional): A boolean that says whether the target\n",
      "     |          for each example is class number (for compatibility with\n",
      "     |          the MNIST dataloader) or a torch vector containing the\n",
      "     |          full qmnist information. Default=True.\n",
      "     |      download (bool, optional): If true, downloads the dataset from\n",
      "     |          the internet and puts it in root directory. If dataset is\n",
      "     |          already downloaded, it is not downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that\n",
      "     |          takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform\n",
      "     |          that takes in the target and transforms it.\n",
      "     |      train (bool,optional,compatibility): When argument 'what' is\n",
      "     |          not specified, this boolean decides whether to load the\n",
      "     |          training set ot the testing set.  Default: True.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, what: Union[str, NoneType] = None, compat: bool = True, train: bool = True, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the QMNIST data if it doesn't exist in processed_folder already.\n",
      "     |      Note that we only download what has been asked for (argument 'what').\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'resources': typing.Dict[str, typing.List[typing.Tu...\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', ...\n",
      "     |  \n",
      "     |  resources = {'nist': [('https://raw.githubusercontent.com/facebookrese...\n",
      "     |  \n",
      "     |  subsets = {'nist': 'nist', 'test': 'test', 'test10k': 'test', 'test50k...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class SBDataset(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SBDataset(*args, **kwds)\n",
      "     |  \n",
      "     |  `Semantic Boundaries Dataset <http://home.bharathh.info/pubs/codes/SBD/download.html>`_\n",
      "     |  \n",
      "     |  The SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset.\n",
      "     |  \n",
      "     |  .. note ::\n",
      "     |  \n",
      "     |      Please note that the train and val splits included with this dataset are different from\n",
      "     |      the splits in the PASCAL VOC dataset. In particular some \"train\" images might be part of\n",
      "     |      VOC2012 val.\n",
      "     |      If you are interested in testing on VOC 2012 val, then use `image_set='train_noval'`,\n",
      "     |      which excludes all val images.\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Semantic Boundaries Dataset\n",
      "     |      image_set (string, optional): Select the image_set to use, ``train``, ``val`` or ``train_noval``.\n",
      "     |          Image set ``train_noval`` excludes VOC 2012 val images.\n",
      "     |      mode (string, optional): Select target type. Possible values 'boundaries' or 'segmentation'.\n",
      "     |          In case of 'boundaries', the target is an array of shape `[num_classes, H, W]`,\n",
      "     |          where `num_classes=20`.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version. Input sample is PIL image and target is a numpy array\n",
      "     |          if `mode='boundaries'` or PIL image if `mode='segmentation'`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SBDataset\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |  \n",
      "     |  __init__(self, root: str, image_set: str = 'train', mode: str = 'boundaries', download: bool = False, transforms: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  filename = 'benchmark.tgz'\n",
      "     |  \n",
      "     |  md5 = '82b4d87ceb2ed10f6038a1cba92111cb'\n",
      "     |  \n",
      "     |  url = 'http://www.eecs.berkeley.edu/Research/Projects/CS/vision/groupi...\n",
      "     |  \n",
      "     |  voc_split_filename = 'train_noval.txt'\n",
      "     |  \n",
      "     |  voc_split_md5 = '79bff800c5f0b1ec6b21080a3c066722'\n",
      "     |  \n",
      "     |  voc_train_url = 'http://home.bharathh.info/pubs/codes/SBD/train_noval....\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class SBU(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SBU(*args, **kwds)\n",
      "     |  \n",
      "     |  `SBU Captioned Photo <http://www.cs.virginia.edu/~vicente/sbucaptions/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where tarball\n",
      "     |          ``SBUCaptionedPhotoDataset.tar.gz`` exists.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SBU\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is a caption for the photo.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = True) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |      The number of photos in the dataset.\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download and extract the tarball, and download each individual photo.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  filename = 'SBUCaptionedPhotoDataset.tar.gz'\n",
      "     |  \n",
      "     |  md5_checksum = '9aec147b3488753cf758b4d493422285'\n",
      "     |  \n",
      "     |  url = 'http://www.cs.virginia.edu/~vicente/sbucaptions/SBUCaptionedPho...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class SEMEION(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SEMEION(*args, **kwds)\n",
      "     |  \n",
      "     |  `SEMEION <http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit>`_ Dataset.\n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``semeion.py`` exists.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SEMEION\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = True) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  filename = 'semeion.data'\n",
      "     |  \n",
      "     |  md5_checksum = 'cb545d371d2ce14ec121470795a77432'\n",
      "     |  \n",
      "     |  url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/semeio...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class STL10(torchvision.datasets.vision.VisionDataset)\n",
      "     |  STL10(*args, **kwds)\n",
      "     |  \n",
      "     |  `STL10 <https://cs.stanford.edu/~acoates/stl10/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``stl10_binary`` exists.\n",
      "     |      split (string): One of {'train', 'test', 'unlabeled', 'train+unlabeled'}.\n",
      "     |          Accordingly dataset is selected.\n",
      "     |      folds (int, optional): One of {0-9} or None.\n",
      "     |          For training, loads one of the 10 pre-defined folds of 1k samples for the\n",
      "     |           standard evaluation procedure. If no value is passed, loads the 5k samples.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      STL10\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', folds: Union[int, NoneType] = None, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'stl10_binary'\n",
      "     |  \n",
      "     |  class_names_file = 'class_names.txt'\n",
      "     |  \n",
      "     |  filename = 'stl10_binary.tar.gz'\n",
      "     |  \n",
      "     |  folds_list_file = 'fold_indices.txt'\n",
      "     |  \n",
      "     |  splits = ('train', 'train+unlabeled', 'unlabeled', 'test')\n",
      "     |  \n",
      "     |  test_list = [['test_X.bin', '7f263ba9f9e0b06b93213547f721ac82'], ['tes...\n",
      "     |  \n",
      "     |  tgz_md5 = '91f7769df0f17e558f3565bffb0c7dfb'\n",
      "     |  \n",
      "     |  train_list = [['train_X.bin', '918c2871b30a85fa023e0c44e0bee87f'], ['t...\n",
      "     |  \n",
      "     |  url = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class SVHN(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SVHN(*args, **kwds)\n",
      "     |  \n",
      "     |  `SVHN <http://ufldl.stanford.edu/housenumbers/>`_ Dataset.\n",
      "     |  Note: The SVHN dataset assigns the label `10` to the digit `0`. However, in this Dataset,\n",
      "     |  we assign the label `0` to the digit `0` to be compatible with PyTorch loss functions which\n",
      "     |  expect the class labels to be in the range `[0, C-1]`\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load data from `.mat` format.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``SVHN`` exists.\n",
      "     |      split (string): One of {'train', 'test', 'extra'}.\n",
      "     |          Accordingly dataset is selected. 'extra' is Extra training set.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SVHN\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  split_list = {'extra': ['http://ufldl.stanford.edu/housenumbers/extra_...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class UCF101(torchvision.datasets.vision.VisionDataset)\n",
      "     |  UCF101(*args, **kwds)\n",
      "     |  \n",
      "     |  `UCF101 <https://www.crcv.ucf.edu/data/UCF101.php>`_ dataset.\n",
      "     |  \n",
      "     |  UCF101 is an action recognition video dataset.\n",
      "     |  This dataset consider every video as a collection of video clips of fixed size, specified\n",
      "     |  by ``frames_per_clip``, where the step in frames between each clip is given by\n",
      "     |  ``step_between_clips``.\n",
      "     |  \n",
      "     |  To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n",
      "     |  and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n",
      "     |  elements will come from video 1, and the next three elements from video 2.\n",
      "     |  Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n",
      "     |  frames in a video might be present.\n",
      "     |  \n",
      "     |  Internally, it uses a VideoClips object to handle clip creation.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the UCF101 Dataset.\n",
      "     |      annotation_path (str): path to the folder containing the split files\n",
      "     |      frames_per_clip (int): number of frames in a clip.\n",
      "     |      step_between_clips (int, optional): number of frames between each clip.\n",
      "     |      fold (int, optional): which fold to use. Should be between 1 and 3.\n",
      "     |      train (bool, optional): if ``True``, creates a dataset from the train split,\n",
      "     |          otherwise from the ``test`` split.\n",
      "     |      transform (callable, optional): A function/transform that  takes in a TxHxWxC video\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      video (Tensor[T, H, W, C]): the `T` video frames\n",
      "     |      audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n",
      "     |          and `L` is the number of points\n",
      "     |      label (int): class of the video clip\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UCF101\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, root, annotation_path, frames_per_clip, step_between_clips=1, frame_rate=None, fold=1, train=True, transform=None, _precomputed_metadata=None, num_workers=1, _video_width=0, _video_height=0, _video_min_dimension=0, _audio_samples=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  metadata\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class USPS(torchvision.datasets.vision.VisionDataset)\n",
      "     |  USPS(*args, **kwds)\n",
      "     |  \n",
      "     |  `USPS <https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#usps>`_ Dataset.\n",
      "     |  The data-format is : [label [index:value ]*256 \\n] * num_lines, where ``label`` lies in ``[1, 10]``.\n",
      "     |  The value for each pixel lies in ``[-1, 1]``. Here we transform the ``label`` into ``[0, 9]``\n",
      "     |  and make pixel values in ``[0, 255]``.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset to store``USPS`` data files.\n",
      "     |      train (bool, optional): If True, creates dataset from ``usps.bz2``,\n",
      "     |          otherwise from ``usps.t.bz2``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      USPS\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  split_list = {'test': ['https://www.csie.ntu.edu.tw/~cjlin/libsvmtools...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class VOCDetection(torchvision.datasets.vision.VisionDataset)\n",
      "     |  VOCDetection(*args, **kwds)\n",
      "     |  \n",
      "     |  `Pascal VOC <http://host.robots.ox.ac.uk/pascal/VOC/>`_ Detection Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the VOC Dataset.\n",
      "     |      year (string, optional): The dataset year, supports years 2007 to 2012.\n",
      "     |      image_set (string, optional): Select the image_set to use, ``train``, ``trainval`` or ``val``\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |          (default: alphabetic indexing of VOC's 20 classes).\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, required): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VOCDetection\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is a dictionary of the XML tree.\n",
      "     |  \n",
      "     |  __init__(self, root: str, year: str = '2012', image_set: str = 'train', download: bool = False, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, transforms: Union[Callable, NoneType] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  parse_voc_xml(self, node: xml.etree.ElementTree.Element) -> Dict[str, Any]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class VOCSegmentation(torchvision.datasets.vision.VisionDataset)\n",
      "     |  VOCSegmentation(*args, **kwds)\n",
      "     |  \n",
      "     |  `Pascal VOC <http://host.robots.ox.ac.uk/pascal/VOC/>`_ Segmentation Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the VOC Dataset.\n",
      "     |      year (string, optional): The dataset year, supports years 2007 to 2012.\n",
      "     |      image_set (string, optional): Select the image_set to use, ``train``, ``trainval`` or ``val``\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VOCSegmentation\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is the image segmentation.\n",
      "     |  \n",
      "     |  __init__(self, root: str, year: str = '2012', image_set: str = 'train', download: bool = False, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, transforms: Union[Callable, NoneType] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class VisionDataset(torch.utils.data.dataset.Dataset)\n",
      "     |  VisionDataset(*args, **kwds)\n",
      "     |  \n",
      "     |  An abstract class representing a :class:`Dataset`.\n",
      "     |  \n",
      "     |  All datasets that represent a map from keys to data samples should subclass\n",
      "     |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "     |  data sample for a given key. Subclasses could also optionally overwrite\n",
      "     |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      "     |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "     |  of :class:`~torch.utils.data.DataLoader`.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      "     |    sampler that yields integral indices.  To make it work with a map-style\n",
      "     |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Any\n",
      "     |  \n",
      "     |  __init__(self, root: str, transforms: Union[Callable, NoneType] = None, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n",
      "DATA\n",
      "    __all__ = ('LSUN', 'LSUNClass', 'ImageFolder', 'DatasetFolder', 'FakeD...\n",
      "\n",
      "FILE\n",
      "    d:\\programfiles\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.datasets -- Overview\n",
    "\n",
    "**PACKAGES**\n",
    "\n",
    "    caltech\n",
    "    celeba\n",
    "    cifar\n",
    "    cityscapes\n",
    "    coco\n",
    "    fakedata\n",
    "    flickr\n",
    "    folder\n",
    "    hmdb51\n",
    "    imagenet\n",
    "    kinetics\n",
    "    lsun\n",
    "    mnist\n",
    "    omniglot\n",
    "    phototour\n",
    "    places365\n",
    "    samplers (package)\n",
    "    sbd\n",
    "    sbu\n",
    "    semeion\n",
    "    stl10\n",
    "    svhn\n",
    "    ucf101\n",
    "    usps\n",
    "    utils\n",
    "    video_utils\n",
    "    vision\n",
    "    voc\n",
    "\n",
    "\n",
    "**CLASSES**\n",
    "\n",
    "- torchvision.datasets.vision.VisionDataset(torch.utils.data.dataset.Dataset)\n",
    "    - torchvision.datasets.caltech.Caltech101\n",
    "    - torchvision.datasets.caltech.Caltech256\n",
    "    - torchvision.datasets.celeba.CelebA\n",
    "    - torchvision.datasets.cifar.CIFAR10\n",
    "        - torchvision.datasets.cifar.CIFAR100\n",
    "    - torchvision.datasets.cityscapes.Cityscapes\n",
    "    - torchvision.datasets.coco.CocoCaptions\n",
    "    - torchvision.datasets.coco.CocoDetection\n",
    "    - torchvision.datasets.fakedata.FakeData\n",
    "    - torchvision.datasets.flickr.Flickr30k\n",
    "    - torchvision.datasets.flickr.Flickr8k\n",
    "    - torchvision.datasets.folder.DatasetFolder\n",
    "        - torchvision.datasets.folder.ImageFolder\n",
    "            - torchvision.datasets.imagenet.ImageNet\n",
    "    - torchvision.datasets.hmdb51.HMDB51\n",
    "    - torchvision.datasets.kinetics.Kinetics400\n",
    "    - torchvision.datasets.lsun.LSUN\n",
    "    - torchvision.datasets.lsun.LSUNClass\n",
    "    - torchvision.datasets.mnist.MNIST\n",
    "        - torchvision.datasets.mnist.EMNIST\n",
    "        - torchvision.datasets.mnist.FashionMNIST\n",
    "        - torchvision.datasets.mnist.KMNIST\n",
    "        - torchvision.datasets.mnist.QMNIST\n",
    "    - torchvision.datasets.omniglot.Omniglot\n",
    "    - torchvision.datasets.phototour.PhotoTour\n",
    "    - torchvision.datasets.sbd.SBDataset\n",
    "    - torchvision.datasets.sbu.SBU\n",
    "    - torchvision.datasets.semeion.SEMEION\n",
    "    - torchvision.datasets.stl10.STL10\n",
    "    - torchvision.datasets.svhn.SVHN\n",
    "    - torchvision.datasets.ucf101.UCF101\n",
    "    - torchvision.datasets.usps.USPS\n",
    "    - torchvision.datasets.voc.VOCDetection\n",
    "    - torchvision.datasets.voc.VOCSegmentation\n",
    "\n",
    "\n",
    "**FILE**: \\torchvision\\datasets\\\\\\_\\_init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets.cifar.CIFAR10\n",
    "```python\n",
    "datasets.CIFAR10(\n",
    "    root,\n",
    "    train=True,\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    "    download=False,\n",
    ")\n",
    "```\n",
    "**说明**\n",
    "\n",
    "[CIFAR10数据集](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "**参数**\n",
    "- root: 该数据集会被保存至`root`目录下的``cifar-10-batches-py``文件内\n",
    "- train: 默认`True`，这种情况下从训练集中创建数据，否则从测试集创建数据\n",
    "- transform: 可调用对象，该函数以 PIL 图像为输入，并返回被转换后的图像的函数，如``transforms.RandomCrop``\n",
    "- target_transform: 接收标签并将其进行转换的可调用对象\n",
    "- download: 若为 True，则下载数据集并保存至指定目录下，若数据集已经存在则不会执行下载操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets.Cityscapes()\n",
    "```python\n",
    "datasets.Cityscapes(\n",
    "    root: str,\n",
    "    split: str = 'train',\n",
    "    mode: str = 'fine',\n",
    "    target_type: Union[List[str], str] = 'instance',\n",
    "    transform: Union[Callable, NoneType] = None,\n",
    "    target_transform: Union[Callable, NoneType] = None,\n",
    "    transforms: Union[Callable, NoneType] = None\n",
    ")\n",
    "```\n",
    "[Cityscapes Dataset](http://www.cityscapes-dataset.com/)，该数据集需要手动下载；\n",
    "\n",
    "**Args**\n",
    "- root: ``leftImg8bit``和``gtFine``或``gtCoarse``所在的目录\n",
    "- split: 表示所使用的数据集；`mode=\"fine\"`时可以是``train``、``val``、``test``；其他情况可以是``train``、``train_extra``、``val``；\n",
    "- mode: 使用的数据集质量，可以是`fine`或`coarse`；\n",
    "- target_type: 所使用的标签的种类，支持的种类包括``instance``、``semantic``、``polygon``、``color``；所传递的可以是单个字符串，也可以是字符串组成的列表；后者返回的标签为所有指定类型的标签组成的元祖；\n",
    "- transform: 可调用函数，该函数以 PIL 图像为输入，并返回被转换后的图像的函数，如``transforms.RandomCrop``\n",
    "- target_transform: 接收标签并将其进行转换的可调用对象\n",
    "- transforms: 以输入数据和标签作为输入的函数，并返回转换后的结果\n",
    "\n",
    "**File**:   \\torchvision\\datasets\\cityscapes.py\n",
    "\n",
    "**Type**:           type\n",
    "\n",
    "### Examples\n",
    "\n",
    "```python\n",
    "# ==> Using multiple targets\n",
    "dataset = Cityscapes(\n",
    "    './data/cityscapes', split='train', mode='fine',\n",
    "    target_type=['semantic', 'instance', 'color', 'polygon'])\n",
    "img, (smnt, inst, col, poly) = dataset[0]\n",
    "\n",
    "# ==> Using the \"coarse\" set\n",
    "dataset = Cityscapes(\n",
    "    './data/cityscapes', split='val',\n",
    "    mode='coarse', target_type='semantic')\n",
    "img, smnt = dataset[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets.VOCSegmentation()\n",
    "```python\n",
    "datasets.VOCSegmentation(\n",
    "    root: str,\n",
    "    year: str = '2012',\n",
    "    image_set: str = 'train',\n",
    "    download: bool = False,\n",
    "    transform: Union[Callable, NoneType] = None,\n",
    "    target_transform: Union[Callable, NoneType] = None,\n",
    "    transforms: Union[Callable, NoneType] = None\n",
    ")\n",
    "```\n",
    "\n",
    "[Pascal VOC Segmentation Dataset](http://host.robots.ox.ac.uk/pascal/VOC/)\n",
    "\n",
    "**Args**\n",
    "- root: VOC 数据集下载至的根目录\n",
    "- year: 数据集的年份，支持 2007 ~ 2012\n",
    "- image_set: 所使用的数据集，可以是``train``、``trainval``、``val``\n",
    "- download: 若为 True，则下载数据集并保存至指定目录下，若数据集已经存在则不会执行下载操作\n",
    "- transform: 可调用函数，该函数以 PIL 图像为输入，并返回被转换后的图像的函数，如``transforms.RandomCrop``\n",
    "- target_transform: 接收标签并将其进行转换的可调用对象\n",
    "- transforms: 以输入数据和标签作为输入的函数，并返回转换后的结果\n",
    "\n",
    "**File**:     \\torchvision\\datasets\\voc.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets.VOCDetection()\n",
    "```python\n",
    "datasets.VOCDetection(\n",
    "    root: str,\n",
    "    year: str = '2012',\n",
    "    image_set: str = 'train',\n",
    "    download: bool = False,\n",
    "    transform: Union[Callable, NoneType] = None,\n",
    "    target_transform: Union[Callable, NoneType] = None,\n",
    "    transforms: Union[Callable, NoneType] = None\n",
    ")\n",
    "```\n",
    "\n",
    "[Pascal VOC Detection Dataset](http://host.robots.ox.ac.uk/pascal/VOC/)\n",
    "\n",
    "**Args**\n",
    "- root: VOC 数据集下载至的根目录\n",
    "- year: 数据集的年份，支持 2007 ~ 2012\n",
    "- image_set: 所使用的数据集，可以是``train``、``trainval``、``val``\n",
    "- download: 若为 True，则下载数据集并保存至指定目录下，若数据集已经存在则不会执行下载操作\n",
    "- transform: 可调用函数，该函数以 PIL 图像为输入，并返回被转换后的图像的函数，如``transforms.RandomCrop``\n",
    "- target_transform: 接收标签并将其进行转换的可调用对象\n",
    "- transforms: 以输入数据和标签作为输入的函数，并返回转换后的结果\n",
    "**File**:     \\torchvision\\datasets\\voc.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.datasets.ImageFolder()\n",
    "```python\n",
    "torchvision.datasets.ImageFolder(\n",
    "    root,\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    "    loader=<function default_loader at 0x000001E0B2EFD5E8>,\n",
    "    is_valid_file=None,\n",
    ")\n",
    "```\n",
    "**Docstring**\n",
    "\n",
    "一个通用的数据加载器，其中的图像以以下方式进行整理：\n",
    "```bash\n",
    "root/dog/xxx.png\n",
    "root/dog/xxy.png\n",
    "root/dog/xxz.png\n",
    "\n",
    "root/cat/123.png\n",
    "root/cat/nsdf3.png\n",
    "root/cat/asd932_.png\n",
    "```\n",
    "\n",
    "**Args**\n",
    "- root: 根目录\n",
    "- transform: 一个以 PIL 图像作为输入，并返回一个变换后的图像的函数或`transform`，如``transforms.RandomCrop``\n",
    "- target_transform: 一个以 target 作为输入并对其进行变换的函数或`transform`\n",
    "- loader: 根据其路径加载图像的函数\n",
    "- is_valid_file: 一个以图像文件的路径作为输入，并检查该文件是否为有效文件的函数（该参数之前一直用于检查损坏的文件\n",
    "\n",
    "**Attributes**\n",
    "- classes: 一个按字母排序的类的名称组成的列表\n",
    "- class_to_idx: `{class_name: class_index}`形式的字典\n",
    "- imgs: `(image path, class_index)`形式的元组组成的列表\n",
    "\n",
    "**File**:  torchvision\\datasets\\folder.py\n",
    "\n",
    "**Type**:           type\n",
    "\n",
    "**Subclasses**:     ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.datasets.ImageFolder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
