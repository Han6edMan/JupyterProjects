{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.Compose\n",
    "\n",
    "`transforms.Compose(transforms)`\n",
    "\n",
    "**Docstring**: \n",
    "\n",
    "将几个`transform`组合起来\n",
    "\n",
    "**Args**\n",
    "\n",
    "- `transforms`: `transforms`组成的列表\n",
    "\n",
    "**File**:  \\torchvision\\transforms\\transforms.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.Normalize()\n",
    "`transforms(mean, std, inplace=False)`\n",
    "\n",
    "**Doctring**\n",
    "\n",
    "在 channel 层级上对图像进行归一化，该函数不会改变输入张量\n",
    "\n",
    "**Args**\n",
    "\n",
    "- `mean`: 每一channel的平均值组成的序列；\n",
    "- `std`: 每一channel的标准差组成的序列；\n",
    "- `inplace`: 是否对输入值做修改，`False`时该函数不改变输入值，\n",
    "\n",
    "**File**:   \\torchvision\\transforms\\transforms.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.ToTensor()\n",
    "\n",
    "**说明**: \n",
    "\n",
    "若`PIL Image`为 (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) 中的一种，以及若`numpy.ndarray`的数据类型为`np.unit8`，则可以将一个`PIL Image`或一个范围在$[0, 255]$ 的 $H\\times W\\times C$ 的`numpy.ndarray`转换成一个范围在 $[0.0, 1.0]$ 的 $H\\times W\\times C$ 的`torch.FloatTensor` \n",
    "\n",
    "其他情况则返回一个没有经过放缩的tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.RandomCrop\n",
    "```py\n",
    "transforms.RandomCrop(\n",
    "    size,\n",
    "    padding=None,\n",
    "    pad_if_needed=False,\n",
    "    fill=0,\n",
    "    padding_mode='constant'\n",
    ")\n",
    "```\n",
    "  \n",
    "**Docstring**\n",
    "\n",
    "将给定的 PIL Image 依据`size`随机裁剪\n",
    "\n",
    "**参数**\n",
    "\n",
    "- size: 裁剪后输出的形状，为一整数时输出形状为` (size, size)`，为一序列`(h, w)`时则以指明形状输出\n",
    "\n",
    "- padding: 若其值为 4 元序列，则序列元素分别分配至图像左侧、上部、右侧、下部的填充值；若其值为 2 元序列，则序列元素分别分配至图像水平和竖直方向的填充值；若其值为一整数，略\n",
    "\n",
    "- pad_if_needed: 当输入图像形状小于输出时会填充图片，防止报错；Since cropping is done after padding, the padding seems to be done at a random offset\n",
    "\n",
    "- fill: 填充模式为常数时的填充值，若为3元数组，则分别填充至 R, G, B 通道中\n",
    "\n",
    "- padding_mode: 填充模式，包括`constant`, `edge`, `reflect`, `symmetric`\n",
    "\n",
    "    - constant: padding 由`fill`给定的值\n",
    "    \n",
    "    - edge: 由图像边缘像素点的取值pad\n",
    "    \n",
    "    - reflect: 根据图像像素点取值，以不重复边缘像素点取值的方式对称地填充，如像素点为 $[1, 2, 3, 4]$ 则填充值为 $[3, 2, 1, 2, 3, 4, 3, 2]$\n",
    "    \n",
    "    - symmetric: 根据图像像素点取值，以重复边缘像素点取值的方式对称地填充，如像素点为 $[1, 2, 3, 4]$ 则填充值为 $[2, 1, 1, 2, 3, 4, 4, 3]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.RandomResizedCrop()\n",
    "```py\n",
    "transforms.RandomResizedCrop(\n",
    "    size,\n",
    "    scale=(0.08, 1.0),\n",
    "    ratio=(0.75, 1.3333333333333333),\n",
    "    interpolation=2,\n",
    ")\n",
    "```\n",
    "**Docstring**\n",
    "\n",
    "对于给定的 PIL 图像，以原始大小的随机大小和原始高宽比的随机高宽比进行裁剪，裁剪结果最终会调整到给定的大小，其常用于训练 Inception 网络\n",
    "\n",
    "**Args**\n",
    "- size: 略\n",
    "- scale: 原始图像被裁剪的范围\n",
    "- ratio: 原长高比被裁剪的范围\n",
    "- interpolation: 默认为`PIL.Image.BILINEAR`\n",
    "\n",
    "**File**:       \\torchvision\\transforms\\transforms.py\n",
    "\n",
    "**Type**:           type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.RandomHorizontalFlip()\n",
    "\n",
    "**声明**\n",
    "\n",
    "transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "**说明**\n",
    "\n",
    "以给定的概率水平翻转给定的PIL图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
