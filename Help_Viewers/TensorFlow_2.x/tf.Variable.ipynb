{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Variable()\n",
    "```python\n",
    "tf.Variable(\n",
    "    initial_value=None,\n",
    "    trainable=None,\n",
    "    validate_shape=True,\n",
    "    caching_device=None,\n",
    "    name=None,\n",
    "    variable_def=None,\n",
    "    dtype=None,\n",
    "    import_scope=None,\n",
    "    constraint=None,\n",
    "    synchronization=VariableSynchronization.AUTO,\n",
    "    aggregation=VariableAggregation.NONE,\n",
    "    shape=None)\n",
    "```\n",
    "\n",
    "\n",
    "__Docstring__\n",
    "\n",
    "见[variable guide](https://tensorflow.org/guide/variable).\n",
    "\n",
    "用于声明一个由程序操作的、保持着共享性和持久性的`Variable`对象。\n",
    "\n",
    "__Args__\n",
    "    \n",
    "    \n",
    "- initial_value: 张量或可转换为张量的 Python 对象，是`Variable`的初始化取值；除`validate_shape`被指明为`False`外，需指明初始值的形状；`initial_value`也可以是也可以是不带参数的可调用函数，其在调用时返回初始值，这种情况下`dtype`必须被指明。(注意`init_ops.py`的初始化函数在调用前必须首先绑定到一个形状上)\n",
    "\n",
    "- trainable: 当 `synchronization`被设定为`ON_READ`时，其默认值为`False`，否则默认值为`True`；当其取值为`True`时，`GradientTapes`将自动记录这个变量的使用情况。\n",
    "\n",
    "- validate_shape: 取值为`False`时，该变量可以用一个形状未知的值初始化，否则变量形状必须被指明\n",
    "\n",
    "- caching_device: 字符串型变量，用于指明应在何处缓存变量以进行读取，默认为变量所在的设备；取值不为`None`时则缓存到另一个设备上，典型的用法是在使用变量驻留的Ops设备(where the Ops using the Variable reside)上缓存，以能够通过`Switch`和其他条件语句来减少重复的拷贝(deduplicate copying)\n",
    "\n",
    "- name: 变量的名称，默认为`'Variable'`并自动实现实例唯一化(uniquified)\n",
    "\n",
    "- variable_def: `VariableDef`协议缓冲区(protocol buffer)；若取值不为`None`，则根据该变量在计算图中的节点，重新创建变量对象及其内容；这要求其在计算图中的节点应必须存在，但不会对计算图进行更改。`variable_def`和其他参数是互斥的，当其与`inital_value`同时被指明时会报错\n",
    "\n",
    "- dtype: 当没有指明类型时，即其取值为`None`时，若`initial_value`为一张量，则该变量的数据类型将被保留；若`initial_value`不为张量，则数据类型由`convert_to_tensor`决定\n",
    "\n",
    "- import_scope: `Variable`的名称作用域，仅在从协议缓冲区初始化时使用\n",
    "\n",
    "- constraint: 被`Optimizer`更新后作用在变量上的投影函数，如用于对该层权重的范数约束或值约束的函数；该函数必须以表示变量值的未投影张量作为输入，并返回投影值的张量，返回张量应与原张量形状相同。在进行异步分布式训练时，使用约束并不安全\n",
    "\n",
    "- synchronization: 用于指明分布式变量是什么时候被聚合(aggregated)的。支持由`tf.VariableSynchronization`类定义的变量；默认情况下，同步状态设置为`AUTO`，并由当前的`DistributionStrategy`决定何时同步\n",
    "\n",
    "- aggregation: 用于指明分布式变量是如何被聚合的，支持由`tf.VariableAggregation`类定义的变量\n",
    "\n",
    "- shape: `None`时使用`initial_value`的形状，当设定为`tf.TensorShape(None)`时，即表示一个未指定的形状，该变量可被设定为任意形状\n",
    "\n",
    "See the `tf.function` documentation for details.\n",
    "\n",
    "\n",
    "__WARNING__：有些参数已被弃用`(caching_device)`，这些参数在未来版本中将被移除。\n",
    "\n",
    "__Instructions for updating__\n",
    "\n",
    "- 可以通过在tf.device作用域下调用tf.Variable.read_value()来手动缓存变量的值。\n",
    "\n",
    "- caching_device参数有时不能正常工作。\n",
    "\n",
    "\n",
    "__Type__: VariableMetaclass\n",
    "\n",
    "__Subclasses__: VariableV1, DistributedVariable, AggregatingVariable, AutoCastVariable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Variable()`构造函数要求变量有一个初始值，该变量类型可以为任意形状任意类型的 `Tensor`，这个初始值定义了该变量的类型和形状，构造完成后其类型和形状便已固定，其值可以通过 assign 方法修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=2.0>\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=2.5>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(1.)\n",
    "print(x.assign(2.))\n",
    "print(x.assign_add(0.5))  # 注意输出为 tf.Variable\n",
    "x = x + 1  # 该操作使 x 变为 tf.Tensor 类型，进而无法使用assign修改及赋值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "声明一个形状未完全定义的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(1., shape=tf.TensorShape(None))\n",
    "print(x)\n",
    "print(x.assign([[1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有为`Tensor`类重载的运算符都被转移到variables中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable([[1.], [2.]])\n",
    "x = tf.constant([[3., 4.]])\n",
    "y = tf.matmul(w, x)\n",
    "z = tf.sigmoid(w + x)\n",
    "print(w, x, y, z, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trainable`和`tf.GradientTape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    trainable = tf.Variable(1.)\n",
    "    non_trainable = tf.Variable(2., trainable=False)\n",
    "    x1 = trainable * 2.\n",
    "    x2 = non_trainable * 3.\n",
    "print(tape.gradient(x1, trainable))\n",
    "print(tape.gradient(x2, non_trainable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当变量包含有继承`tf.Module`类型的属性时，变量会被自动跟踪；该追踪允许将变量值保存到包括了序列化的计算图的\n",
    "[training checkpoints](https://www.tensorflow.org/guide/checkpoint)或\n",
    "[SavedModels](https://www.tensorflow.org/guide/saved_model)中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.Module()\n",
    "m.v = tf.Variable([1.])\n",
    "print(m.trainable_variables)\n",
    "print(m.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables经常被‘tf.function’捕获和操纵。这与未修饰函数的工作方式相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.1, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.2, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(0.)\n",
    "read_and_decrement = tf.function(lambda: v.assign_sub(0.1))\n",
    "print(read_and_decrement())\n",
    "print(read_and_decrement())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`tf.function`中创建的变量必须在函数外部拥有，并且只创建一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(tf.Module):\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        if not hasattr(self, \"v\"):  # Or set self.v to None in __init__\n",
    "        self.v = tf.Variable(x)\n",
    "        return self.v * x\n",
    "m = M()\n",
    "m(2.)\n",
    "m(3.)\n",
    "m.v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x.assign_sub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
