{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data.Dataset.from_tensor_slices()\n",
    "***\n",
    "`tf.data.Dataset.from_tensor_slices(tensors)`\n",
    "\n",
    "__Docstring__\n",
    "\n",
    "`tensors`为张量构成的数据集，所有张量第一维形状必须相同；该函数沿着它们的第一维度将`tensors`进行切片；这个操作保留了各张量的结构，移除了每个张量的第一个维数，并使用它作为数据集维数；\n",
    "\n",
    "注意：若`tensors`包含 Numpy 数组并且预期的操作无法执行，这些值会作为一个或多个`tf.constant`嵌入至计算图中；对于大型数据集(> 1 GB)，这可能会浪费内存并遇到图形序列化的字节限制；若`tensors`包含一个或多个大型 Numpy 数组，须考虑另外的可行方案[this guide](\n",
    "https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
    "\n",
    "__Type__: function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a 1D tensor produces scalar tensor elements.\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "for k, v in dataset.__dict__.items():\n",
    "    print(k, v, sep=\"\\n\")\n",
    "    print()\n",
    "print(list(dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a 2D tensor produces 1D tensor elements.\n",
    "dataset = tf.data.Dataset.from_tensor_slices([[1, 2, 3], [3, 4, 5], [4, 5, 6]])\n",
    "print(dataset._tensors)\n",
    "for element in dataset.as_numpy_iterator():\n",
    "    print(element)\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a tuple of 1D tensors produces tuple elements containing\n",
    "dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3], [3, 4, 5], [5, 6, 7]))\n",
    "print(dataset._tensors, end=\"\\n\\n\")\n",
    "for element in dataset.as_numpy_iterator():\n",
    "    print(element)\n",
    "for data in dataset:\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary structure is also preserved.\n",
    "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2, 3], \"b\": [3, 4, 5]})\n",
    "print(dataset._tensors, end=\"\\n\\n\")\n",
    "for element in dataset.as_numpy_iterator():\n",
    "    print(element)\n",
    "for data in dataset:\n",
    "    print(data, end=\"\\n\\n\")\n",
    "for k, v in dataset.__dict__.items():\n",
    "    print(k, v, sep=\"\\n\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3])>, <tf.Tensor: shape=(), dtype=string, numpy=b'A'>)\n",
      "\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 1])>, <tf.Tensor: shape=(), dtype=string, numpy=b'B'>)\n",
      "\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3])>, <tf.Tensor: shape=(), dtype=string, numpy=b'A'>)\n",
      "\n",
      "(array([1, 3]), b'A')\n",
      "\n",
      "(array([2, 1]), b'B')\n",
      "\n",
      "(array([3, 3]), b'A')\n",
      "\n",
      "[<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "array([[1, 3],\n",
      "       [2, 1],\n",
      "       [3, 3]])>, <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'A', b'B', b'A'], dtype=object)>]\n"
     ]
    }
   ],
   "source": [
    "# Two tensors can be combined into one Dataset object.\n",
    "features = tf.constant([[1, 3], [2, 1], [3, 3]])\n",
    "labels = tf.constant(['A', 'B', 'A'])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "for data in dataset:\n",
    "    print(data, end=\"\\n\\n\")\n",
    "for element in dataset.as_numpy_iterator():\n",
    "    print(element, end=\"\\n\\n\")\n",
    "print(dataset._tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([1, 3]), b'A'), (array([2, 1]), b'B'), (array([3, 3]), b'A')]\n",
      "\n",
      "(array([1, 3]), b'A')\n",
      "(array([2, 1]), b'B')\n",
      "(array([3, 3]), b'A')\n"
     ]
    }
   ],
   "source": [
    "# Both the features and the labels tensors can be converted to a Dataset object separately and combined after.\n",
    "features_dataset = Dataset.from_tensor_slices(features)\n",
    "labels_dataset = Dataset.from_tensor_slices(labels)\n",
    "dataset = Dataset.zip((features_dataset, labels_dataset))\n",
    "\n",
    "for element in dataset.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1, 3],\n",
      "       [2, 3]]), array([[b'A'],\n",
      "       [b'A']], dtype=object))\n",
      "(array([[2, 1],\n",
      "       [1, 2]]), array([[b'B'],\n",
      "       [b'B']], dtype=object))\n",
      "(array([[3, 3],\n",
      "       [3, 2]]), array([[b'A'],\n",
      "       [b'B']], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "# A batched feature and label set can be converted to a Dataset in similar fashion.\n",
    "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
    "                                [[2, 1], [1, 2]],\n",
    "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
    "batched_labels = tf.constant([['A', 'A'],\n",
    "                              ['B', 'B'],\n",
    "                              ['A', 'B']], shape=(3, 2, 1))\n",
    "dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
    "for element in dataset.as_numpy_iterator():\n",
    "    print(element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
